{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Simple Agent in Python\n",
    "\n",
    "Welcome to this tutorial on building a simple agent in Python! In this notebook, we will focus on creating a basic agent that can communicate with a **Large Language Model (LLM)** to perform tasks autonomously. We will build upon the concepts you learned in the previous notebook, such as prompts and LLM interaction, and now put those into practice to create a functional agent.\n",
    "\n",
    "By the end of this tutorial, you will know how to configure a simple agent, interact with an LLM, and process the responses it provides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is an AI Agent?\n",
    "\n",
    "An **AI Agent** is a system that can use a **Large Language Model (LLM)** to understand, reason, plan, and execute tasks. It operates autonomously, meaning it can perform actions and make decisions with minimal human input. AI agents can handle complex problems by breaking them down into smaller steps, using tools, accessing memory, and adjusting their behavior based on the context provided.\n",
    "\n",
    "At its core, an AI agent is designed to:\n",
    "\n",
    "1. **Receive a task**: Take input from the user, such as a question or command.\n",
    "2. **Plan a solution**: Break down the problem, select appropriate tools, and reason through possible solutions.\n",
    "3. **Execute the plan**: Perform actions, such as retrieving information or generating responses, based on the plan it has created.\n",
    "4. **Respond with the result**: Present the final output in a structured and actionable format.\n",
    "\n",
    "![agent](images/agentic-vs-non-agentic.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Components of an AI Agent:\n",
    "\n",
    "- **Agent Core**: The central decision-making unit that defines the goals of the agent, selects tools, and coordinates task execution.\n",
    "- **Memory Module**: Tracks the agent’s past interactions. This can include short-term memory (for current tasks) or long-term memory (for ongoing interactions over time).\n",
    "- **Tools**: External resources or APIs that the agent can use to perform specific tasks, like retrieving data, interacting with other systems, or performing calculations.\n",
    "- **Planning Module**: Helps the agent break down complex tasks into smaller, more manageable sub-tasks. It allows the agent to handle sophisticated queries by decomposing them into simpler steps.\n",
    "- **State Management**: State management is an essential concept when working with agents. The \"state\" of an agent refers to its current condition or the information it has at any given time. For instance, if an agent is working through a list of tasks, its state might include which tasks have been completed, which are in progress, and which are yet to be started. *Managing this state is crucial because it allows the agent to keep track of what it has done and what it needs to do next. Without proper state management, an agent might lose track of its progress, repeat tasks, or skip important steps. In this notebook, you'll learn how to manage an agent's state effectively, ensuring that it operates smoothly and efficiently.*\n",
    "\n",
    "### Example:\n",
    "\n",
    "Imagine an agent designed to help with financial analysis. When asked, \"What are the three key takeaways from the Q2 earnings call for FY 2023?\", the agent doesn’t just search for a single piece of information. Instead, it breaks the query into multiple steps:\n",
    "1. Identify relevant sections of the earnings call.\n",
    "2. Analyze the key points about technology or business developments.\n",
    "3. Present the findings clearly to the user.\n",
    "\n",
    "In this way, an AI agent uses the reasoning capabilities of an LLM combined with external tools to provide a comprehensive response.\n",
    "\n",
    "![agent](images/agent.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout this notebook, we will keep things simple, focusing on building the core functionality of the agent, so you can see how everything fits together in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up the Environment\n",
    "\n",
    "Before we can communicate with the LLM, let’s install any required libraries and ensure our environment is ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in ./.conda/lib/python3.11/site-packages (2.32.3)\n",
      "Requirement already satisfied: jsonschema in ./.conda/lib/python3.11/site-packages (4.23.0)\n",
      "Requirement already satisfied: tenacity in ./.conda/lib/python3.11/site-packages (8.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.conda/lib/python3.11/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.conda/lib/python3.11/site-packages (from requests) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.conda/lib/python3.11/site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.conda/lib/python3.11/site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./.conda/lib/python3.11/site-packages (from jsonschema) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./.conda/lib/python3.11/site-packages (from jsonschema) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./.conda/lib/python3.11/site-packages (from jsonschema) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./.conda/lib/python3.11/site-packages (from jsonschema) (0.20.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install requests jsonschema tenacity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These packages are used for:\n",
    "\n",
    "- **requests:** Making HTTP requests to interact with models.\n",
    "- **jsonschema:** Validating the structure of the agent's output.\n",
    "- **tenacity:** Handling retries in case of errors when communicating with the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datetime Function\n",
    "\n",
    "We'll create is a simple function to get the current time. This is important because our agent might need to timestamp certain actions or events. Let's write a function that returns the current date and time in UTC format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current UTC datetime: 2024-09-06 18:41:14.438990 \n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timezone\n",
    "\n",
    "\n",
    "def get_current_utc_datetime():\n",
    "    now_utc = datetime.now(timezone.utc)\n",
    "    return now_utc.strftime(\"%Y-%m-%d %H:%M:%S.%f UTC\")[:-3]\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "print(\"Current UTC datetime:\", get_current_utc_datetime())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuring a Simple Model\n",
    "\n",
    "In this section, we configure the machine learning model that our agent will use to process tasks. The `ModelService` class manages the interaction with the model (in this case, \"llama3.1:8b-instruct-fp16\"), allowing the agent to handle tasks such as listing VMs and retrieving details.\n",
    "\n",
    "### Model Configuration\n",
    "\n",
    "We initialize the `ModelService` with a specific model configuration, including parameters such as model endpoint, temperature (for controlling randomness), and others. This step enables our agent to perform model-based tasks using the provided configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from services.model_service import ModelService\n",
    "\n",
    "# Initialize the service with the model configuration\n",
    "ollama_service = ModelService(model=\"llama3.1:latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. System Prompt for the Simple Agent\n",
    "\n",
    "In this cell, we define the **System Prompt** for our agent. The system prompt helps set the behavior of the agent when interacting with the **Large Language Model (LLM)**. This particular prompt instructs the LLM to act as a helpful assistant, focused on answering questions clearly and concisely.\n",
    "\n",
    "### Key Aspects of the System Prompt:\n",
    "1. **Assistant Role:** The agent is instructed to provide useful, clear, and concise responses to user queries.\n",
    "2. **Guidelines:**\n",
    "   - **Clear Responses:** The agent is expected to give direct and simple answers to the user's questions.\n",
    "   - **Avoid Unnecessary Details:** It avoids overloading the user with too much information—responses should be brief and relevant.\n",
    "   - **Polite Tone:** The agent will always maintain a friendly and helpful tone in its responses.\n",
    "   - **Answer Format:** Responses are expected to be returned in simple text, with no special formatting unless specifically requested by the user.\n",
    "   \n",
    "### Example Interaction:\n",
    "This system prompt also includes an example to illustrate the expected behavior of the agent:\n",
    "- If the user asks, \"What is Python used for?\", the agent will respond with something like:\n",
    "  - \"Python is a versatile programming language used for web development, data analysis, automation, and more.\"\n",
    "\n",
    "This **System Prompt** ensures that the agent remains consistent in how it responds, providing useful and easy-to-understand answers in all cases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYS_PROMPT = \"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "Cutoff Knowledge Date: December 2023\n",
    "Current Date: {datetime}\n",
    "\n",
    "You are a helpful assistant. Your job is to answer questions clearly and concisely. Make sure your responses are easy to understand and provide useful information.\n",
    "\n",
    "---\n",
    "\n",
    "### Example Interaction:\n",
    "\n",
    "User: \"What is Python used for?\"\n",
    "\n",
    "Assistant: \"Python is a versatile programming language used for web development, data analysis, automation, and more.\"\n",
    "\n",
    "---\n",
    "\n",
    "### Key Points:\n",
    "- **Be Direct:** Answer only what is asked, without extra information.\n",
    "- **Be Polite:** Maintain a friendly and helpful tone.\n",
    "<|eot_id|>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Agent Class for Interacting with the LLM\n",
    "\n",
    "In this cell, we define the `Agent` class, which serves as the core component responsible for interacting with the **Large Language Model (LLM)**. This class is designed to handle the interaction between user input and the LLM, process the model's responses, and maintain an internal state.\n",
    "\n",
    "### Key Components:\n",
    "\n",
    "1. **Initialization (`__init__`):**\n",
    "   - The `Agent` class is initialized with:\n",
    "     - `state`: A dictionary to track the agent's current state.\n",
    "     - `role`: The defined role of the agent (e.g., \"assistant\").\n",
    "     - `ollama_service`: A service interface that handles communication with the LLM (in this case, represented by `ModelService`).\n",
    "\n",
    "2. **State Management (`update_state`):**\n",
    "   - The `update_state` method allows the agent to update its internal state based on key-value pairs. This helps the agent track progress or store important data.\n",
    "   - If the agent tries to update a state key that doesn't exist, it will warn the user.\n",
    "\n",
    "3. **Model Interaction (`invoke_model`):**\n",
    "   - This is the core method that interacts with the LLM. It prepares the input payload by combining the **system prompt** and **user prompt**.\n",
    "   - The payload is then sent to the model service (`ollama_service`), which communicates with the LLM, retrieves the response, and processes it.\n",
    "   - The final processed response from the model is returned for further use.\n",
    "\n",
    "4. **Main Task Execution (`work`):**\n",
    "   - The `work` method is the primary interface for executing tasks based on user input.\n",
    "   - It formats the **system prompt** (using a predefined prompt template) and combines it with the **user prompt** (the user's specific question or request).\n",
    "   - The `work` method then invokes the model and returns the final response from the LLM.\n",
    "   - This method can be easily extended for more complex tasks.\n",
    "\n",
    "### Example Workflow:\n",
    "- The agent receives a **user request**.\n",
    "- It prepares the system and user prompts and sends them to the model.\n",
    "- The LLM processes the input and returns a response.\n",
    "- The agent processes the LLM’s response and returns the final output.\n",
    "\n",
    "This structure makes it easy to build on top of the agent, allowing you to handle more complex interactions, manage state efficiently, and extend the agent’s behavior over time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any\n",
    "\n",
    "\n",
    "class Agent:\n",
    "\n",
    "    def __init__(self, state: Dict[str, Any], role: str, ollama_service: ModelService):\n",
    "        \"\"\"\n",
    "        Initialize the Agent with a state, role, and model configuration.\n",
    "        \"\"\"\n",
    "        self.state = state\n",
    "        self.role = role\n",
    "        self.ollama_service = ollama_service\n",
    "\n",
    "    def update_state(self, key: str, value: Any):\n",
    "        \"\"\"\n",
    "        Update the state of the agent. Warn if the key doesn't exist.\n",
    "        \"\"\"\n",
    "        if key in self.state:\n",
    "            self.state[key] = value\n",
    "        else:\n",
    "            print(f\"Warning: Attempting to update a non-existing state key '{key}'.\")\n",
    "\n",
    "    def invoke_model(self, sys_prompt: str, user_prompt: str):\n",
    "        \"\"\"\n",
    "        Prepare the payload, send the request to the model, and process the response.\n",
    "        \"\"\"\n",
    "        # Prepare the payload\n",
    "        payload = self.ollama_service.prepare_payload(\n",
    "            user_prompt,\n",
    "            sys_prompt,\n",
    "        )\n",
    "\n",
    "        # Invoke the model and get the response\n",
    "        response_json = self.ollama_service.request_model_generate(\n",
    "            payload,\n",
    "        )\n",
    "\n",
    "        # Process the model's response\n",
    "        response_content = self.ollama_service.process_model_response(response_json)\n",
    "\n",
    "        # Return the processed response\n",
    "        return response_content\n",
    "\n",
    "    def work(\n",
    "        self,\n",
    "        user_request: str,\n",
    "        sys_prompt: str = SYS_PROMPT,\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Execute a simple task based on the user's request.\n",
    "        \"\"\"\n",
    "        # Define a simple system prompt\n",
    "        formatted_sys_prompt = sys_prompt.format(datetime=get_current_utc_datetime())\n",
    "        user_prompt = f\"\"\"<|start_header_id|>user<|end_header_id|>\\n\\n{user_request}<|eot_id|>\n",
    "            <|start_header_id|>assistant<|end_header_id|>\"\"\"\n",
    "\n",
    "        # Invoke the model with the user's request\n",
    "        response = self.invoke_model(\n",
    "            sys_prompt=formatted_sys_prompt, user_prompt=user_prompt\n",
    "        )\n",
    "\n",
    "        # Return the processed response\n",
    "        return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Agent\n",
    "\n",
    "Finally, let's demonstrate how to run the agent with a simple example. We'll use the agent class we've just implemented to process a task based on user input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent's response: {\n",
      "    \"name\": \"Tesla\",\n",
      "    \"description\": \"Tesla, Inc., commonly known as Tesla, is an American multinational corporation that specializes in electric vehicle (EV) manufacturing and clean energy technologies.\",\n",
      "    \"founder\": \"Elon Musk\",\n",
      "    \"founding_date\": \"2003\",\n",
      "    \"headquarters\": \"Austin, Texas\",\n",
      "    \"products\": {\n",
      "        \"vehicles\": [\n",
      "            {\n",
      "                \"model_s\": \"Sedan, SUVs, trucks, and Cybertruck\",\n",
      "                \"features\": \"Autopilot technology, long-range battery options, all-wheel drive\"\n",
      "            },\n",
      "            {\n",
      "                \"Model X\": \"Full-size luxury SUV with falcon-wing doors\",\n",
      "                \"features\": \"Panoramic windshield, semi-autonomous driving capabilities\"\n",
      "            },\n",
      "            {\n",
      "                \"Cybertruck\": \"Electric pickup truck\",\n",
      "                \"features\": \"Blazer-like bed liner, quad-motor setup, glass roof\"\n",
      "            }\n",
      "        ],\n",
      "        \"solar_products\": [\n",
      "            {\n",
      "                \"SolarRoof\": \"A photovoltaic solar shingle product designed for homes\",\n",
      "                \"features\": \"Self-healing glass tiles, seamless integration into existing roofs\"\n",
      "            },\n",
      "            {\n",
      "                \"Powerwall\": \"An energy storage battery system for residential and commercial use\",\n",
      "                \"capacity\": \"25 kWh to 100 kWh options, grid management capabilities\"\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Initialize the agent with an empty state and a role\n",
    "agent_state = {\"response\": \"\"}\n",
    "agent_role = \"Helper Agent\"\n",
    "agent = Agent(state=agent_state, role=agent_role, ollama_service=ollama_service)\n",
    "\n",
    "# Execute a task\n",
    "user_input = \"Tell me everything you know about Tesla.\"\n",
    "response = agent.work(user_request=user_input)\n",
    "print(\"Agent's response:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Switching to Llama 3.1 Instruct Model\n",
    "\n",
    "In this section, we switch our model to **Llama 3.1 Instruct**, specifically designed for applications that combine both conversation and tool-calling. The Llama 3.1 Instruct model can generate responses while simultaneously utilizing built-in tools such as **Brave Search** and **Wolfram Alpha** to retrieve real-time information or perform complex calculations.\n",
    "\n",
    "### Why Use Llama 3.1 Instruct?\n",
    "\n",
    "The **Instruct** model is optimized for tool-based interactions and can:\n",
    "- **Handle Tool Calls:** Automatically call tools such as Brave Search or Wolfram Alpha to answer questions that require real-time data or mathematical computation.\n",
    "- **Generate Python Code:** In environments like `ipython`, the model can directly generate Python code, which can be executed to provide results.\n",
    "- **Custom Tools:** Allow developers to define custom tools within prompts, enabling the agent to make intelligent decisions based on available resources.\n",
    "\n",
    "### Setting Up the Model Service\n",
    "\n",
    "We initialize the **Llama 3.1 Instruct** model service below. This service is designed to manage interactions between the agent and the model, facilitating tool usage when required.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the service with the model configuration\n",
    "ollama_instruct_service = ModelService(model=\"llama3.1:8b-instruct-fp16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Updated System Prompt for Tool Use\n",
    "\n",
    "In this section, we define a **System Prompt** specifically for the **Llama 3.1 Instruct** model. This prompt activates tool usage within the model, allowing the agent to utilize built-in tools like **Brave Search** when necessary.\n",
    "\n",
    "### Key Changes to the System Prompt:\n",
    "- **Environment Setup:** The model operates within an `ipython` environment, automatically enabling code interpretation.\n",
    "- **Tools Definition:** The model can now call **Brave Search** when real-time information is requested.\n",
    "- **Instructions for Real-Time Queries:** If the required data isn’t available in the model’s training set, the agent falls back to calling **Brave Search** for web-based answers.\n",
    "\n",
    "This **System Prompt** instructs the agent to respond concisely and clearly, and enables it to use **Brave Search** when real-time data is needed, making the agent more dynamic and adaptable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTRUCT_SYS_PROMPT = \"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "Environment: ipython\n",
    "Tools: brave_search\n",
    "Cutoff Knowledge Date: December 2023\n",
    "Today’s Date: {datetime}\n",
    "\n",
    "You are a helpful and concise assistant. Your role is to provide accurate, direct, and easy-to-understand answers in a friendly tone. For real-time information, use brave_search. If real-time data is unavailable, inform the user politely.<|eot_id|>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Running the Updated Agent with Tool Support\n",
    "\n",
    "Now that we have set up the **Llama 3.1 Instruct** model and the updated system prompt with tool integration, let’s test the agent by asking it a question that requires real-time information. In this example, the agent uses **Brave Search** to retrieve the latest news on Tesla.\n",
    "\n",
    "In this example, the agent sends the request to the **Llama 3.1 Instruct** model, which will decide if it needs to call **Brave Search** to find the most recent information about Tesla. The result is then processed and returned to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent's response: {\n",
      "    \"search_term\": \"latest news on Tesla\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Initialize the agent with an empty state and a role\n",
    "agent_state = {\"response\": \"\"}\n",
    "agent_role = \"Helper Agent\"\n",
    "agent = Agent(\n",
    "    state=agent_state, role=agent_role, ollama_service=ollama_instruct_service\n",
    ")\n",
    "\n",
    "# Execute a task\n",
    "user_input = \"What are the lastest knews on Tesla.\"\n",
    "response = agent.work(user_request=user_input, sys_prompt=INSTRUCT_SYS_PROMPT)\n",
    "print(\"Agent's response:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "\n",
    "In this notebook, we’ve built a **simple AI-powered agent** that interacts with a **Large Language Model (LLM)** to answer user queries. Let’s recap what we've accomplished:\n",
    "\n",
    "- **Defined the agent's behavior** through a **System Prompt**, instructing the LLM on how to respond to questions.\n",
    "- **Created the `Agent` class** to manage interactions between the user and the LLM.\n",
    "- **Implemented state management** to allow the agent to track progress or other necessary information.\n",
    "- **Configured a model service** to handle communication between the agent and the LLM, enabling it to retrieve and process responses.\n",
    "- **Executed the agent** with a user query, receiving a helpful response from the LLM.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
