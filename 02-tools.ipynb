{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Tools calling\n",
    "\n",
    "In this notebook, we will explore how the LLM can use external tools to enhance its capabilities. We'll begin by adding and configuring a search tool to allow the LLM to perform real-time searches.\n",
    "\n",
    "By the end of this notebook, you'll be able to integrate and configure external search tools with a language model, and use them to perform real-time searches and enhance responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User, LLM, Tools\n",
    "\n",
    "![image](images/llm_tools_llama.jpeg)\n",
    "Source: [Llama 3.1 Instruct](https://llama.meta.com/docs/model-cards-and-prompt-formats/llama3_1)\n",
    "\n",
    "1. **User Submits a Prompt**: The process starts when the user provides input or a prompt, which is sent to the **Executor** for handling.\n",
    "2. **Executor Forwards Prompt to LLM**: The **Executor** forwards the userâ€™s prompt to the **Llama Model** (LLM) for initial processing.\n",
    "3. **LLM Processes the Prompt**: The **LLM** analyzes the prompt and determines whether it can generate a response directly or if external tools are needed to complete the request.\n",
    "4. **LLM Requests External Tool Invocation**: If external data or additional resources are required (e.g., real-time data from a search engine or a code interpreter), the **Llama Model** signals the **Executor** to call the relevant tool.\n",
    "5. **Executor Calls the Tools**: The **Executor** initiates the tool request, calling external tools (such as Brave Search, Wolfram Alpha, Code Interpreter, or other custom tools) to fetch necessary information.\n",
    "6. **Tools Retrieve Data**: The external tools access the required information from outside environments (e.g., fetching real-time search results or performing complex calculations) and return the data to the **Executor**.\n",
    "7. **Executor Synthesizes Final Response**: The **Executor** combines the original prompt, the **LLM**'s processing, and any external tool responses. The final response is then sent back to the **LLM**.\n",
    "8. **LLM Generates Final Response**: The **LLM** synthesizes all the gathered data and generates a final response.\n",
    "9. **Executor Sends Response to User**: The **Executor** delivers the final response back to the user, completing the interaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "Before we begin, let's make sure your environment is set up correctly. We'll start by installing the necessary Python packages.\n",
    "\n",
    "### Installing Required Packages\n",
    "\n",
    "To get started, you'll need to install a few Python libraries. Run the following command to install them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: termcolor in ./.conda/lib/python3.11/site-packages (2.4.0)\n",
      "Requirement already satisfied: langchain_community in ./.conda/lib/python3.11/site-packages (0.2.16)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.conda/lib/python3.11/site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.conda/lib/python3.11/site-packages (from langchain_community) (2.0.34)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.conda/lib/python3.11/site-packages (from langchain_community) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./.conda/lib/python3.11/site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.16 in ./.conda/lib/python3.11/site-packages (from langchain_community) (0.2.16)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.38 in ./.conda/lib/python3.11/site-packages (from langchain_community) (0.2.38)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in ./.conda/lib/python3.11/site-packages (from langchain_community) (0.1.110)\n",
      "Requirement already satisfied: numpy<2,>=1 in ./.conda/lib/python3.11/site-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in ./.conda/lib/python3.11/site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in ./.conda/lib/python3.11/site-packages (from langchain_community) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.8)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.conda/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./.conda/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in ./.conda/lib/python3.11/site-packages (from langchain<0.3.0,>=0.2.16->langchain_community) (0.2.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in ./.conda/lib/python3.11/site-packages (from langchain<0.3.0,>=0.2.16->langchain_community) (2.8.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.conda/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.38->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./.conda/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.38->langchain_community) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./.conda/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.38->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.conda/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (0.25.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.conda/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.conda/lib/python3.11/site-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.conda/lib/python3.11/site-packages (from requests<3,>=2->langchain_community) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.conda/lib/python3.11/site-packages (from requests<3,>=2->langchain_community) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.conda/lib/python3.11/site-packages (from requests<3,>=2->langchain_community) (2024.8.30)\n",
      "Requirement already satisfied: anyio in ./.conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (4.4.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./.conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (1.0.5)\n",
      "Requirement already satisfied: sniffio in ./.conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.conda/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.conda/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.38->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.conda/lib/python3.11/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.16->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./.conda/lib/python3.11/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.16->langchain_community) (2.20.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.conda/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install termcolor langchain_community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These packages are used for:\n",
    "\n",
    "- **termcolor:** Adding colored text output to the terminal, which is useful for debugging and improving the readability of logs and outputs.\n",
    "- **langchain_community:** To enable the LLM to perform real-time searches, we need to install the `duckduckgo-search` library using the `langchain_community` package. This will allow the agent to search the web using DuckDuckGo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuring a Simple Model\n",
    "\n",
    "In this section, we configure the machine learning model that we will use to process tasks. The `ModelService` class manages the interaction with the model (in this case, \"llama3.1:8b-instruct-fp16\").\n",
    "\n",
    "### Model Configuration\n",
    "\n",
    "We initialize the `ModelService` with a specific model configuration, including parameters such as model endpoint, temperature (for controlling randomness), and others. This step enables us to perform model-based tasks using the provided configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from services.model_service import ModelService\n",
    "\n",
    "# Initialize the service with the model configuration\n",
    "ollama_service = ModelService(model=\"llama3.1:8b-instruct-fp16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoking the Model\n",
    "\n",
    "The `invoke_model` function handles the communication between the system and the language model. It takes two inputs: `sys_prompt` (system prompt) and `user_prompt` (the user's input), and performs the following steps:\n",
    "\n",
    "1. **Prepare the Payload**: Combines the prompts into a format the model can understand.\n",
    "2. **Send the Request**: Sends the prepared data to the model.\n",
    "3. **Process the Response**: Once the model returns a response, it processes the output into a usable format.\n",
    "\n",
    "The function returns the final processed response, which will be used to guide further actions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_model(sys_prompt: str, user_prompt: str):\n",
    "    \"\"\"\n",
    "    Prepare the payload, send the request to the model, and process the response.\n",
    "    \"\"\"\n",
    "    # Prepare the payload\n",
    "    payload = ollama_service.prepare_payload(\n",
    "        user_prompt,\n",
    "        sys_prompt,\n",
    "    )\n",
    "\n",
    "    # Invoke the model and get the response\n",
    "    response_json = ollama_service.request_model_generate(\n",
    "        payload,\n",
    "    )\n",
    "\n",
    "    # Process the model's response\n",
    "    response_content = ollama_service.process_model_response(response_json)\n",
    "\n",
    "    # Return the processed response\n",
    "    return response_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. DuckDuckGo Search Tool\n",
    "\n",
    "First, we will configure the tool by initializing the DuckDuckGo search functionality. This will be the primary tool for real-time search queries in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Tool Name: duckduckgo_search\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "# Initialize DuckDuckGo Search Tool\n",
    "duckduckgo_search = DuckDuckGoSearchRun()\n",
    "\n",
    "# Verify tool name\n",
    "print(\"Search Tool Name:\", duckduckgo_search.name)\n",
    "\n",
    "# Adding the search tool to the list of available tools\n",
    "tools = [duckduckgo_search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools Name:\n",
      " duckduckgo_search\n",
      "Tools Description:\n",
      " duckduckgo_search - A wrapper around DuckDuckGo Search. Useful for when you need to answer questions about current events. Input should be a search query., args: {{'query': {{'title': 'Query', 'description': 'search query to look up', 'type': 'string'}}}}\n"
     ]
    }
   ],
   "source": [
    "# Render tool description to ensure it's ready for LLM usage\n",
    "from langchain.tools.render import render_text_description_and_args\n",
    "\n",
    "tools_name = duckduckgo_search.name\n",
    "\n",
    "tools_description = (\n",
    "    render_text_description_and_args(tools).replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    ")\n",
    "print(\"Tools Name:\\n\", tools_name)\n",
    "print(\"Tools Description:\\n\", tools_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. System Prompt for Tool Integration\n",
    "\n",
    "Now that the DuckDuckGo search tool is set up, we need to write the system prompt to provide tool usage instructions. The LLM will reference this prompt when deciding whether to call the tool.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_prompt = \"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "Environment: ipython\n",
    "Tools: {tools_name}\n",
    "Cutting Knowledge Date: December 2023\n",
    "Today's Date: 23 July 2024\n",
    "\n",
    "---\n",
    "\n",
    "You are an intelligent assistant designed to handle various tasks, including answering questions, providing summaries, and performing detailed analyses. All outputs must strictly be in JSON format.\n",
    "\n",
    "---\n",
    "\n",
    "## Tools\n",
    "You have access to a variety of tools to assist in completing tasks. You are responsible for determining the appropriate sequence of tool usage to break down complex tasks into subtasks when necessary.\n",
    "\n",
    "The available tools include:\n",
    "\n",
    "{tools_description}\n",
    "\n",
    "# Tool Instructions\n",
    "- Always use the available tools when asked for real-time or updated information.\n",
    "- If you choose to call a function ONLY reply in the following format:\n",
    "\n",
    "{{\n",
    "  \"action\": \"Specify the tool you want to use.\",\n",
    "  \"action_input\": {{ # Provide valid JSON input for the action, ensuring it matches the toolâ€™s expected format and data types.\n",
    "    \"key\": \"Value inputs to the tool in valid JSON format.\"\n",
    "  }}\n",
    "}}\n",
    "\n",
    "Example:\n",
    "\n",
    "{{\n",
    "  \"action\": \"duckduckgo_search\",\n",
    "  \"action_input\": {{\n",
    "    \"query\": \"Key features of large language models\"\n",
    "  }} \n",
    "}} \n",
    "\n",
    "Reminder:\n",
    "- Do not include additional metadata such as `title`, `description`, or `type` in the `tool_input`\n",
    "- Function calls MUST follow the specified format\n",
    "- Required parameters MUST be specified\n",
    "- Only call one function at a time\n",
    "- Put the entire function call reply on one line\n",
    "\n",
    "You are a helpful assistant.<|eot_id|>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format the System Prompt\n",
    "\n",
    "Now we will insert the tool descriptions and finalize the system prompt by formatting it to include the correct tool name and description. This prompt will guide the LLM in calling the DuckDuckGo search tool when necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_sys_prompt = sys_prompt.format(\n",
    "    tools_name=tools_name, tools_description=tools_description\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. LLM Request\n",
    "\n",
    "We will now make a request, asking the LLM to search for the latest trends related to Large Language Models. This time, the LLM will have the ability to return the a payload that represents a call to the DuckDuckGo search tool to retrieve real-time information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM response: {\n",
      "    \"action\": \"hugging_face_hub\",\n",
      "    \"action_input\": {\n",
      "        \"model\": \"list-models\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "user_request = \"What are the most recent Large Language Models?\"\n",
    "\n",
    "response = invoke_model(sys_prompt=sys_prompt, user_prompt=user_request)\n",
    "print(\"LLM response:\", response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Processing Tool Actions\n",
    "\n",
    "After the LLM provides its response, we will process the action request. If the LLM calls the DuckDuckGo search tool, we will execute the function and retrieve the results. The tool's output will then be formatted and displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool hugging_face_hub not found or unsupported operation.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "response_dict = json.loads(response)\n",
    "action = response_dict[\"action\"]\n",
    "action_input = response_dict[\"action_input\"]\n",
    "\n",
    "for tool in tools:\n",
    "    if tool.name == action:\n",
    "        print(tool.name)\n",
    "        try:\n",
    "            result = tool.invoke(action_input)\n",
    "            result_message = (\n",
    "                f\"\"\"<|start_header_id|>ipython<|end_header_id|>\\n\\n{result}<|eot_id|>\"\"\"\n",
    "            )\n",
    "            print(result_message)\n",
    "        except Exception as e:\n",
    "            print(f\"Error executing tool {action}: {str(e)}\")\n",
    "    else:\n",
    "        print(f\"Tool {action} not found or unsupported operation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    " \n",
    "In this notebook, we've successfully extended the capabilities of the LLM by integrating an external tool (DuckDuckGo search). We covered:\n",
    "\n",
    "- **LLM and Tool Integration:** How to modify the system prompt for tool access.\n",
    "- **Tool Setup and Configuration:** Setting up the DuckDuckGo search tool for real-time information retrieval.\n",
    "- **Making Requests and Handling Responses:** Using the tool during LLM interactions and processing the results.\n",
    "\n",
    "With these tools in place, you're now equipped to extend the LLM's capabilities even further by adding more tools and refining its behavior. Happy coding!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
