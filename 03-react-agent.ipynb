{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a ReAct Agent with Tool Integration\n",
    "\n",
    "In this notebook, you will learn how to create and deploy a ReAct (Reasoning + Acting) agent capable of solving complex tasks by combining logical reasoning with external tool usage. The agent will use a structured loop of **Thought → Action → Observation** to iteratively reason through problems, gather data, and provide solutions.\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "\n",
    "- Implement a ReAct agent that breaks down complex user queries into smaller, manageable steps.\n",
    "- Integrate external tools (e.g., calculators, data retrieval functions) that the agent can use to enhance its problem-solving abilities.\n",
    "- Efficiently handle tool outputs and errors, allowing the agent to adapt its actions based on real-time feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Concepts\n",
    "\n",
    "Before implementing a ReAct agent, it's important to understand the foundational concepts.\n",
    "\n",
    "A **ReAct Agent (Reasoning + Acting)** alternates between reasoning through a task and taking actions using external tools. It operates in a loop of **Thought → Action → Observation** until it reaches a final answer or decides no further action is needed.\n",
    "\n",
    "The **Thought → Action → Observation Loop** is the core of the ReAct agent’s operation. It reasons through a problem, chooses the appropriate tool or action, observes the results, and then decides the next step. This process continues iteratively until the task is completed.\n",
    "\n",
    "**Tool Integration** enables the agent to use external functions or APIs to perform actions, such as retrieving data or making calculations. The agent selects tools dynamically based on its reasoning.\n",
    "\n",
    "**Error Handling and Feedback Loops** ensure the agent can recover from failures or unexpected results. If a tool fails or produces incorrect output, the agent adjusts its reasoning and continues to process the task.\n",
    "\n",
    "**Prompt Engineering** is crucial for guiding the ReAct agent’s decisions. Carefully designed prompts allow the agent to use tools efficiently and respond effectively based on the information gathered.\n",
    "\n",
    "These concepts will provide the foundation to build a ReAct agent capable of reasoning through tasks, using tools, and delivering structured, actionable results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "Before we begin, let's make sure your environment is set up correctly. We'll start by installing the necessary Python packages.\n",
    "\n",
    "### Installing Required Packages\n",
    "\n",
    "To get started, you'll need to install a few Python libraries. Run the following command to install them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in ./.conda/lib/python3.11/site-packages (0.2.16)\n",
      "Requirement already satisfied: langgraph in ./.conda/lib/python3.11/site-packages (0.2.16)\n",
      "Requirement already satisfied: langgraph-checkpoint-sqlite in ./.conda/lib/python3.11/site-packages (1.0.3)\n",
      "Requirement already satisfied: requests in ./.conda/lib/python3.11/site-packages (2.32.3)\n",
      "Requirement already satisfied: termcolor in ./.conda/lib/python3.11/site-packages (2.4.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.conda/lib/python3.11/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.conda/lib/python3.11/site-packages (from langchain) (2.0.34)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.conda/lib/python3.11/site-packages (from langchain) (3.10.5)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.38 in ./.conda/lib/python3.11/site-packages (from langchain) (0.2.38)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in ./.conda/lib/python3.11/site-packages (from langchain) (0.2.4)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in ./.conda/lib/python3.11/site-packages (from langchain) (0.1.110)\n",
      "Requirement already satisfied: numpy<2,>=1 in ./.conda/lib/python3.11/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in ./.conda/lib/python3.11/site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in ./.conda/lib/python3.11/site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<2.0.0,>=1.0.2 in ./.conda/lib/python3.11/site-packages (from langgraph) (1.0.8)\n",
      "Requirement already satisfied: aiosqlite<0.21.0,>=0.20.0 in ./.conda/lib/python3.11/site-packages (from langgraph-checkpoint-sqlite) (0.20.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.conda/lib/python3.11/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.conda/lib/python3.11/site-packages (from requests) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.conda/lib/python3.11/site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.conda/lib/python3.11/site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.8)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in ./.conda/lib/python3.11/site-packages (from aiosqlite<0.21.0,>=0.20.0->langgraph-checkpoint-sqlite) (4.12.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.conda/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.38->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./.conda/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.38->langchain) (24.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.conda/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.25.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.conda/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.conda/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./.conda/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
      "Requirement already satisfied: anyio in ./.conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.4.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./.conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\n",
      "Requirement already satisfied: sniffio in ./.conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.conda/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.conda/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.38->langchain) (3.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain langgraph langgraph-checkpoint-sqlite requests termcolor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These packages are used for:\n",
    "\n",
    "- **requests:** Making HTTP requests to interact with models.\n",
    "- **jsonschema:** Validating the structure of the agent's output.\n",
    "- **tenacity:** Handling retries in case of errors when communicating with the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datetime Function\n",
    "\n",
    "We'll create is a simple function to get the current time. This is important because our agent might need to timestamp certain actions or events. Let's write a function that returns the current date and time in UTC format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current UTC datetime: 2024-09-09 21:10:16.524900 \n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timezone\n",
    "\n",
    "\n",
    "def get_current_utc_datetime():\n",
    "    now_utc = datetime.now(timezone.utc)\n",
    "    return now_utc.strftime(\"%Y-%m-%d %H:%M:%S.%f UTC\")[:-3]\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "print(\"Current UTC datetime:\", get_current_utc_datetime())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuring a Simple Model\n",
    "\n",
    "In this section, we configure the machine learning model that our agent will use to process tasks. The `ModelService` class manages the interaction with the model (in this case, \"llama3.1:8b-instruct-fp16\"), allowing the agent to handle tasks such as listing VMs and retrieving details.\n",
    "\n",
    "### Model Configuration\n",
    "\n",
    "We initialize the `ModelService` with a specific model configuration, including parameters such as model endpoint, temperature (for controlling randomness), and others. This step enables our agent to perform model-based tasks using the provided configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from services.model_service import ModelService\n",
    "\n",
    "# Initialize the service with the model configuration\n",
    "ollama_service = ModelService(model=\"llama3.1:8b-instruct-fp16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Custom Tools\n",
    "\n",
    "In this section, we demonstrate how to integrate custom tools into the ReAct agent's workflow. These tools allow the agent to perform specific actions based on the task requirements. We'll start with a basic calculator tool that can perform fundamental arithmetic operations.\n",
    "\n",
    "### Basic Calculator Tool\n",
    "\n",
    "The `basic_calculator` tool performs basic arithmetic operations like addition, subtraction, multiplication, and division. The tool accepts two numbers and an operation as input and returns the result.\n",
    "\n",
    "#### Supported Operations:\n",
    "- `add`: Adds two numbers.\n",
    "- `subtract`: Subtracts the second number from the first.\n",
    "- `multiply`: Multiplies two numbers.\n",
    "- `divide`: Divides the first number by the second (raises an exception for division by zero).\n",
    "- `modulus`: Finds the remainder when the first number is divided by the second.\n",
    "- `power`: Raises the first number to the power of the second.\n",
    "- Comparison operators: `lt` (less than), `le` (less than or equal to), `eq` (equal to), `ne` (not equal to), `ge` (greater than or equal to), `gt` (greater than).\n",
    "\n",
    "The agent will invoke this tool based on the reasoning process and provide structured input in the form of JSON. Let's take a look at the implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from langchain.tools import tool\n",
    "\n",
    "\n",
    "@tool(parse_docstring=True)\n",
    "def basic_calculator(num1, num2, operation):\n",
    "    \"\"\"\n",
    "    Perform a numeric operation on two numbers based on the input string.\n",
    "\n",
    "    Parameters:\n",
    "    'num1' (int): The first number.\n",
    "    'num2' (int): The second number.\n",
    "    'operation' (str): The operation to perform. Supported operations are 'add', 'subtract',\n",
    "                        'multiply', 'divide', 'floor_divide', 'modulus', 'power', 'lt',\n",
    "                        'le', 'eq', 'ne', 'ge', 'gt'.\n",
    "\n",
    "    Returns:\n",
    "    str: The formatted result of the operation.\n",
    "\n",
    "    Raises:\n",
    "    Exception: If an error occurs during the operation (e.g., division by zero).\n",
    "    ValueError: If an unsupported operation is requested or input is invalid.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the supported operations\n",
    "    operations = {\n",
    "        \"add\": operator.add,\n",
    "        \"subtract\": operator.sub,\n",
    "        \"multiply\": operator.mul,\n",
    "        \"divide\": operator.truediv,\n",
    "        \"floor_divide\": operator.floordiv,\n",
    "        \"modulus\": operator.mod,\n",
    "        \"power\": operator.pow,\n",
    "        \"lt\": operator.lt,\n",
    "        \"le\": operator.le,\n",
    "        \"eq\": operator.eq,\n",
    "        \"ne\": operator.ne,\n",
    "        \"ge\": operator.ge,\n",
    "        \"gt\": operator.gt,\n",
    "    }\n",
    "\n",
    "    # Check if the operation is supported\n",
    "    if operation in operations:\n",
    "        try:\n",
    "            # Perform the operation\n",
    "            result = operations[operation](num1, num2)\n",
    "            result_formatted = (\n",
    "                f\"The answer is: {result}.\\nCalculated with basic_calculator.\"\n",
    "            )\n",
    "            return result_formatted\n",
    "        except Exception as e:\n",
    "            return str(e), \"\\n\\nError during operation execution.\"\n",
    "    else:\n",
    "        return \"\\n\\nUnsupported operation. Please provide a valid operation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [basic_calculator]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. State Management\n",
    "\n",
    "State management is an essential concept when working with agents. The \"state\" of an agent refers to its current condition or the information it has at any given time. For instance, if an agent is working through a list of tasks, its state might include which tasks have been completed, which are in progress, and which are yet to be started. Without proper state management, an agent might lose track of its progress, repeat tasks, or skip important steps. In this notebook, you'll learn how to manage an agent's state effectively, ensuring that it operates smoothly and efficiently.\n",
    "\n",
    "### Implementation of State Management\n",
    "\n",
    "To implement state management for our ReAct agent, we define a structured data model (`AgentGraphState`) that holds all the relevant information the agent needs to function effectively. This model includes:\n",
    "- **Input:** The current command or task that the agent is working on.\n",
    "- **Response:** The outputs or actions the agent has generated.\n",
    "\n",
    "Additionally, we provide a utility function, `update_state`, which allows for updating specific elements of the agent's state. This function ensures that the state is consistently and accurately maintained, which is critical for the agent to operate effectively. By checking for the existence of keys before updating, the function helps prevent errors and maintains the integrity of the state.\n",
    "\n",
    "Together, these components form the backbone of the agent's state management system, enabling it to manage complex workflows and adapt to changes dynamically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph.message import add_messages\n",
    "from typing import Annotated, TypedDict, Any\n",
    "\n",
    "\n",
    "class AgentGraphState(TypedDict):\n",
    "    input: str\n",
    "    response: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "def update_state(state: AgentGraphState, key: str, value: Any):\n",
    "    \"\"\"\n",
    "    Update the state of the agent. Warn if the key doesn't exist.\n",
    "    \"\"\"\n",
    "    if key in state:\n",
    "        state[key] = value\n",
    "    else:\n",
    "        print(f\"Warning: Attempting to update a non-existing state key '{key}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. What is a ReAct Agent?\n",
    "\n",
    "A **ReAct agent** is a specialized type of intelligent agent designed to reason about a task, take appropriate actions, and adapt based on the outcomes of those actions. The term **ReAct** stands for **Reasoning + Acting**, which reflects how the agent alternates between thinking through a problem and interacting with tools or external systems to achieve the desired result.\n",
    "\n",
    "### How Does a ReAct Agent Work?\n",
    "\n",
    "A ReAct agent follows a cycle known as the **Thought → Action → Observation** loop:\n",
    "1. **Thought**: The agent reasons about the task, breaks it down into smaller, manageable parts, and decides which action or tool to use next.\n",
    "2. **Action**: The agent executes the chosen action, such as invoking a tool to perform a calculation or retrieve information.\n",
    "3. **Observation**: After the action is completed, the agent observes the result, evaluates if more steps are necessary, and then returns to the reasoning stage if needed.\n",
    "\n",
    "This cycle repeats until the agent has gathered enough information to provide a complete answer or complete the task.\n",
    "\n",
    "### Why Use a ReAct Agent?\n",
    "\n",
    "The primary benefit of a ReAct agent is its ability to autonomously solve complex problems through a process of reasoning and interaction. Unlike simple agents that just follow pre-defined rules, a ReAct agent can:\n",
    "- **Reason through multi-step tasks**: It can break down complex queries into smaller steps and handle them one by one.\n",
    "- **Adapt to new information**: Based on the outcome of each action, the agent can modify its approach and try different strategies if needed.\n",
    "- **Perform external actions**: ReAct agents can interact with tools, APIs, and systems to gather data, perform calculations, or execute external processes.\n",
    "\n",
    "For example, in the context of our notebook, the ReAct agent uses tools like the `basic_calculator` to perform mathematical operations. The agent reasons about when to use the tool, performs the operation, and observes the result to determine if more actions are needed before completing the task.\n",
    "\n",
    "In summary, a ReAct agent is a versatile, intelligent system capable of reasoning, acting, and learning from its actions to accomplish tasks autonomously, making it highly effective for problem-solving in dynamic environments.\n",
    "\n",
    "![image.png](images/react-diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Prompt\n",
    "\n",
    "The system prompt provides the instructions that guide the agent in reasoning through tasks, using tools, and generating structured responses. It establishes the context, including the environment (e.g., ipython) and knowledge cut-off date (December 2023), ensuring the agent understands the limits of its information.\n",
    "\n",
    "The agent is tasked with using tools to solve problems and must decide which tool to use and in what sequence. Each interaction follows a structured JSON format, ensuring clarity in both tool inputs and outputs.\n",
    "\n",
    "The agent operates in a cycle of **thought → action → observation**:\n",
    "- **Thought**: The agent thinks about the task and determines the next action.\n",
    "- **Action**: The agent selects and uses the appropriate tool.\n",
    "- **Observation**: The agent analyzes the tool's result and decides the next step.\n",
    "\n",
    "This process repeats until the agent reaches a sufficient conclusion to answer the user’s query. If the tool provides a clear result, the agent will stop further actions and present the final answer. If the task cannot be completed, the agent will explain the limitation and provide suggestions.\n",
    "\n",
    "The system prompt ensures that the agent behaves logically, utilizes tools efficiently, and delivers structured and coherent responses.\n",
    "\n",
    "For more details on LLAMA 3.1, refer to the [LLAMA 3.1 Model Card](https://llama.meta.com/docs/model-cards-and-prompt-formats/llama3_1/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SYS_REACT_PROMPT = \"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "Environment: ipython\n",
    "Tools: {tools_name} \n",
    "Knowledge Cutoff Date: December 2023  \n",
    "Current Date: {datetime}\n",
    "\n",
    "You are an intelligent assistant designed to handle various tasks, including answering questions, providing summaries, and performing detailed analyses. All outputs must strictly be in JSON format.\n",
    "\n",
    "---\n",
    "\n",
    "## Tools\n",
    "You have access to a variety of tools to assist in completing tasks. You are responsible for determining the appropriate sequence of tool usage to break down complex tasks into subtasks when necessary.\n",
    "\n",
    "The available tools include:\n",
    "\n",
    "{tools_description}\n",
    "\n",
    "---\n",
    "\n",
    "## Output Format:\n",
    "To complete the task, please use the following format:\n",
    "\n",
    "{{\n",
    "  \"thought\": \"Describe your thought process here, including why a tool may be necessary to proceed.\",\n",
    "  \"action\": \"Specify the tool you want to use.\",\n",
    "  \"action_input\": {{ # Provide valid JSON input for the action, ensuring it matches the tool’s expected format and data types.\n",
    "    \"key\": \"Value inputs to the tool in valid JSON format.\"\n",
    "  }}\n",
    "}}\n",
    "\n",
    "After performing an action, the tool will provide a response in the following format:\n",
    "\n",
    "{{\n",
    "  \"observation\": \"The result of the tool invocation\",\n",
    "}}\n",
    "\n",
    "You should keep repeating the format (thought → action → observation) until you have the answer to the original question. \n",
    "\n",
    "If the tool result is successful and the task is complete:\n",
    "\n",
    "{{\n",
    "  \"answer\": \"I have the answer: {{tool_result}}.\"\n",
    "}}\n",
    "\n",
    "\n",
    "Or, if you cannot answer:\n",
    "\n",
    "{{\n",
    "  \"answer\": \"Sorry, I cannot answer your query.\"\n",
    "}}\n",
    "\n",
    "---\n",
    "\n",
    "### Remember:\n",
    "- **If a tool provides a complete and clear answer, do not continue invoking further tools.**\n",
    "- Use the tools effectively and ensure inputs match the required format exactly as described in the task.\n",
    "- Maintain the JSON format and ensure all fields are filled out correctly.\n",
    "- Do not include additional metadata such as `title`, `description`, or `type` in the `tool_input`.\n",
    "\n",
    "<|eot_id|>\n",
    "{user_prompt}\n",
    "{agent_scratchpad}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Simple Agent Class\n",
    "\n",
    "In this section, we define the core `ReActAgent` class, responsible for managing the lifecycle of an agent that processes tasks based on user requests. This class handles interactions with the language model, executes tools, and manages an action-observation loop until a final answer is generated.\n",
    "\n",
    "### Key Components:\n",
    "\n",
    "1. **Model Invocation (`invoke_model`)**:\n",
    "   - This method prepares the input payload, sends it to the model, and processes the returned response. It serves as the interface for querying the language model with system and user prompts.\n",
    "\n",
    "2. **ReAct Loop (`react`)**:\n",
    "   - This method implements the core thought → action → observation loop:\n",
    "     - The agent begins by processing the user’s request.\n",
    "     - It enters a loop where it interacts with the model, parses responses, and checks for an \"action\" or final \"answer\".\n",
    "     - If an action is required, the agent executes the corresponding tool and observes the result, feeding it back to the model until a final answer is generated.\n",
    "     - This loop ensures continuous interaction and adjustment based on model outputs.\n",
    "\n",
    "3. **Tool Execution (`execute_tool`)**:\n",
    "   - This method simulates the execution of tools based on the action and input provided by the model. In practice, this could involve invoking real-world tools or APIs. The result of the tool's execution is then returned to the agent as an observation.\n",
    "\n",
    "### Workflow:\n",
    "\n",
    "- The agent starts by receiving a user request.\n",
    "- It constructs a system prompt with user input and continuously interacts with the model in a loop until the desired output (an answer) is obtained.\n",
    "- If the model suggests an action, the agent executes the tool corresponding to that action, processes the result, and continues.\n",
    "- The loop concludes once the agent successfully generates a final answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from termcolor import colored\n",
    "from langchain_core.messages.ai import AIMessage\n",
    "from langchain_core.messages import SystemMessage\n",
    "from state.agent_graph import AgentGraphState\n",
    "from services.model_service import ModelService\n",
    "from utils.general.helpers import get_current_utc_datetime\n",
    "from utils.general.tools import get_tools_name, get_tools_description\n",
    "\n",
    "\n",
    "class ReactAgent:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        state: AgentGraphState,\n",
    "        role: str,\n",
    "        tools: list,\n",
    "        ollama_service: ModelService,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the Agent with a state, role, and model configuration.\n",
    "        \"\"\"\n",
    "        self.state = state\n",
    "        self.role = role\n",
    "        self.tools = tools\n",
    "        self.ollama_service = ollama_service\n",
    "\n",
    "    def invoke_model(self, sys_prompt: str, user_prompt: str):\n",
    "        \"\"\"\n",
    "        Prepare the payload, send the request to the model, and process the response.\n",
    "        \"\"\"\n",
    "        # Prepare the payload\n",
    "        payload = self.ollama_service.prepare_payload(\n",
    "            user_prompt,\n",
    "            sys_prompt,\n",
    "        )\n",
    "\n",
    "        # Invoke the model and get the response\n",
    "        response_json = self.ollama_service.request_model_generate(\n",
    "            payload,\n",
    "        )\n",
    "\n",
    "        # Process the model's response\n",
    "        response_content = self.ollama_service.process_model_response(response_json)\n",
    "\n",
    "        # Return the processed response\n",
    "        return response_content\n",
    "\n",
    "    def write_react_prompt(\n",
    "        self,\n",
    "        user_prompt: str = \"\",\n",
    "        agent_scratchpad: str = \"\",\n",
    "    ) -> str:\n",
    "        return DEFAULT_SYS_REACT_PROMPT.format(\n",
    "            user_prompt=user_prompt,\n",
    "            agent_scratchpad=agent_scratchpad,\n",
    "            tools_name=get_tools_name(self.tools),\n",
    "            tools_description=get_tools_description(self.tools),\n",
    "            datetime=get_current_utc_datetime(),\n",
    "        )\n",
    "\n",
    "    # Function to format the scratchpad into a properly indented string\n",
    "    def format_scratchpad(self, scratchpad):\n",
    "        formatted_output = \"\"\n",
    "        for entry in scratchpad:\n",
    "            formatted_output += entry.strip() + \"\\n\"\n",
    "        return formatted_output\n",
    "\n",
    "    def react(self, user_request: str) -> dict:\n",
    "        \"\"\"\n",
    "        Execute the task based on the user's request by following the thought → action → observation loop.\n",
    "        \"\"\"\n",
    "\n",
    "        answer = None\n",
    "\n",
    "        # Start with the user's request as the first input\n",
    "        user_prompt = (\n",
    "            f\"\"\"<|start_header_id|>user<|end_header_id|>\\n\\n{user_request}<|eot_id|>\"\"\"\n",
    "        )\n",
    "\n",
    "        sys_prompt = self.write_react_prompt(user_prompt=user_prompt)\n",
    "        # user_prompt = user_request\n",
    "        tool_response = None\n",
    "        action = None\n",
    "        action_input = None\n",
    "        scratchpad = []\n",
    "\n",
    "        print(colored(user_prompt, \"green\"))\n",
    "\n",
    "        # Loop until a final answer is generated\n",
    "        while answer is None:\n",
    "            # Invoke the model with the system prompt and current user input\n",
    "\n",
    "            response = self.invoke_model(sys_prompt=sys_prompt, user_prompt=user_prompt)\n",
    "\n",
    "            try:\n",
    "                # Parse the response assuming it's in JSON format\n",
    "                response_dict = json.loads(\n",
    "                    response\n",
    "                )  # Assuming response is a JSON object\n",
    "\n",
    "                assistant_message = f\"\"\"<|start_header_id|>assistant<|end_header_id|>\\n\\n{response}<|eot_id|>\"\"\"\n",
    "\n",
    "                print(colored(assistant_message, \"cyan\"))\n",
    "\n",
    "                scratchpad.append(assistant_message)\n",
    "\n",
    "                formatted_scratchpad = self.format_scratchpad(scratchpad)\n",
    "                sys_prompt = self.write_react_prompt(\n",
    "                    user_prompt=user_prompt, agent_scratchpad=formatted_scratchpad\n",
    "                )\n",
    "\n",
    "                action = response_dict.get(\"action\", None)\n",
    "                action_input = response_dict.get(\"action_input\", None)\n",
    "\n",
    "                # If there is an action, execute the corresponding tool\n",
    "                if action:\n",
    "                    status, tool_response = self.execute_tool(action, action_input)\n",
    "\n",
    "                    # Formulate the observation to feed back into the model\n",
    "                    tool_response_dict = {\n",
    "                        \"observation\": tool_response,\n",
    "                    }\n",
    "\n",
    "                    tool_response_json = json.dumps(tool_response_dict, indent=4)\n",
    "\n",
    "                    result_message = f\"\"\"<|start_header_id|>ipython<|end_header_id|>\\n\\n{tool_response_json}<|eot_id|>\"\"\"\n",
    "\n",
    "                    print(colored(result_message, \"yellow\"))\n",
    "\n",
    "                    user_prompt = tool_response_json\n",
    "\n",
    "                # Check if the model has given an answer\n",
    "                if \"answer\" in response_dict:\n",
    "                    answer = response_dict[\"answer\"]\n",
    "\n",
    "            except Exception as e:\n",
    "                print(str(e))\n",
    "                system_message = f\"\"\"<|start_header_id|>ipython<|end_header_id|>\\n\\n{str(e)}<|eot_id|>\"\"\"\n",
    "                scratchpad.append(system_message)\n",
    "                formatted_scratchpad = self.format_scratchpad(scratchpad)\n",
    "                sys_prompt = self.write_react_prompt(\n",
    "                    user_prompt=user_prompt, agent_scratchpad=formatted_scratchpad\n",
    "                )\n",
    "\n",
    "        # Return the final answer\n",
    "        return {\n",
    "            \"response\": AIMessage(content=answer),\n",
    "            \"tool_response\": SystemMessage(content=str(tool_response)),\n",
    "        }\n",
    "\n",
    "    def execute_tool(self, action: str, action_input: dict):\n",
    "        \"\"\"\n",
    "        Simulate the tool execution based on the action and action_input.\n",
    "        In a real-world scenario, this would call the appropriate tool.\n",
    "        \"\"\"\n",
    "        # Simulate some tool actions (this would be replaced by actual tool logic)\n",
    "        tool_message = f\"\"\"<|python_tag|>{action}.call({action_input})\\n<|eom_id|>\"\"\"\n",
    "        print(\n",
    "            colored(\n",
    "                tool_message,\n",
    "                \"magenta\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "        for tool in self.tools:\n",
    "            if tool.name == action:\n",
    "                try:\n",
    "                    result = tool.invoke(action_input)\n",
    "                    result_message = f\"\"\"<|start_header_id|>ipython<|end_header_id|>\\n\\n{result}<|eot_id|>\"\"\"\n",
    "                    print(colored(result_message, \"magenta\"))\n",
    "                    return True, result\n",
    "                except Exception as e:\n",
    "                    return False, f\"Error executing tool {action}: {str(e)}\"\n",
    "        else:\n",
    "            return f\"Tool {action} not found or unsupported operation.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Creating and Compiling the Workflow Graph\n",
    "\n",
    "In this step, we build the workflow graph that represents the agent's process. This graph outlines the sequence of operations, including task execution, validation, and decision-making.\n",
    "\n",
    "### Key Components:\n",
    "- **Node Definitions**: Each node in the graph represents a step in the workflow, such as invoking the ReAct agent.\n",
    "  \n",
    "- **Edge Definitions**: Edges define the flow between nodes, determining how the agent progresses through the tasks and validation steps.\n",
    "\n",
    "- **Workflow Compilation**: Once the graph is defined, it is compiled into a workflow that can be executed.\n",
    "\n",
    "By constructing and compiling this workflow graph, we ensure that the PM agent operates in a structured and efficient manner, handling tasks and making decisions in a logical sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def react_node_function(state: AgentGraphState):\n",
    "    react_agent = ReactAgent(\n",
    "        state=state,\n",
    "        role=\"REACT_AGENT\",\n",
    "        tools=tools,\n",
    "        ollama_service=ollama_service,\n",
    "    )\n",
    "\n",
    "    return react_agent.react(user_request=state[\"input\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "\n",
    "def create_graph() -> StateGraph:\n",
    "    \"\"\"\n",
    "    Create the state graph by defining nodes and edges.\n",
    "\n",
    "    Returns:\n",
    "    - StateGraph: The compiled state graph ready for execution.\n",
    "    \"\"\"\n",
    "    graph = StateGraph(AgentGraphState)\n",
    "\n",
    "    # Add nodes\n",
    "    graph.add_node(\"react_agent\", react_node_function)\n",
    "\n",
    "    # Define the flow of the graph\n",
    "    graph.add_edge(START, \"react_agent\")\n",
    "    graph.add_edge(\"react_agent\", END)\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Sqlite Persistence for Graph State\n",
    "\n",
    "In this cell, we define and use a method to initialize an `SqliteSaver` instance from the `langgraph.checkpoint.sqlite` module. The `SqliteSaver` class allows the graph state to be persisted in an SQLite database, which is more durable and suitable for applications requiring longer-term storage compared to an in-memory solution.\n",
    "\n",
    "The `from_conn_stringx` method is defined as a class method that takes a connection string as input, creates a connection to the SQLite database using `sqlite3.connect`, and then returns an `SqliteSaver` instance using this connection. This method simplifies the creation of an `SqliteSaver` instance directly from a connection string.\n",
    "\n",
    "This approach is particularly useful for ensuring that the state of the `StateGraph` is saved to a local or memory-based SQLite database, enabling the retention of context across multiple interactions in AI-driven applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "def from_conn_stringx(\n",
    "    cls,\n",
    "    conn_string: str,\n",
    ") -> \"SqliteSaver\":\n",
    "    return SqliteSaver(conn=sqlite3.connect(conn_string, check_same_thread=False))\n",
    "\n",
    "\n",
    "SqliteSaver.from_conn_stringx = classmethod(from_conn_stringx)\n",
    "\n",
    "memory = SqliteSaver.from_conn_stringx(\":memory:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Executing the Workflow\n",
    "\n",
    "With the workflow graph compiled, the final step is to execute the workflow. This involves providing the agent with an input query, such as a request to generate a VM migration plan, and allowing the workflow to run through its defined sequence.\n",
    "\n",
    "### Creating and Running the Workflow\n",
    "\n",
    "In this step, we create and execute the PM agent's workflow to process a set of tasks.\n",
    "\n",
    "- **Graph Creation**: \n",
    "  - We first create the workflow graph using `create_graph()` and compile it with a memory-based checkpoint.\n",
    "  - The compiled workflow will manage the task execution, validation, and feedback handling.\n",
    "\n",
    "- **Workflow Parameters**:\n",
    "  - We define the number of iterations (`iterations = 10`), set verbose mode to `True`, and configure the thread ID.\n",
    "  - A query containing three tasks (VM details retrieval, migration plan creation, and migration start) is provided as input.\n",
    "\n",
    "- **Workflow Execution**:\n",
    "  - The workflow is executed using `workflow.stream()`, and it processes each task sequentially.\n",
    "  - Depending on the state of the workflow, feedback or task responses are printed to track progress.\n",
    "\n",
    "This step runs the agent through the defined tasks and prints the state changes for each event in the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph and workflow created.\n",
      "\u001b[32m<|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "What is 10+10?<|eot_id|>\u001b[0m\n",
      "\u001b[36m<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\n",
      "    \"thought\": \"To calculate the result of 10+10, I need to use a tool that can perform addition.\",\n",
      "    \"action\": \"basic_calculator\",\n",
      "    \"action_input\": {\n",
      "        \"num1\": 10,\n",
      "        \"num2\": 10,\n",
      "        \"operation\": \"add\"\n",
      "    }\n",
      "}<|eot_id|>\u001b[0m\n",
      "\u001b[35m<|python_tag|>basic_calculator.call({'num1': 10, 'num2': 10, 'operation': 'add'})\n",
      "<|eom_id|>\u001b[0m\n",
      "\u001b[35m<|start_header_id|>ipython<|end_header_id|>\n",
      "\n",
      "The answer is: 20.\n",
      "Calculated with basic_calculator.<|eot_id|>\u001b[0m\n",
      "\u001b[33m<|start_header_id|>ipython<|end_header_id|>\n",
      "\n",
      "{\n",
      "    \"observation\": \"The answer is: 20.\\nCalculated with basic_calculator.\"\n",
      "}<|eot_id|>\u001b[0m\n",
      "\u001b[36m<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\n",
      "    \"answer\": \"I have the answer: 20.\"\n",
      "}<|eot_id|>\u001b[0m\n",
      "\n",
      "Event: {'react_agent': {'response': AIMessage(content='I have the answer: 20.'), 'tool_response': SystemMessage(content='The answer is: 20.\\nCalculated with basic_calculator.')}}\n"
     ]
    }
   ],
   "source": [
    "# Create the graph and compile the workflow\n",
    "graph = create_graph()\n",
    "workflow = graph.compile(checkpointer=memory)\n",
    "print(\"Graph and workflow created.\")\n",
    "\n",
    "# Define workflow parameters\n",
    "iterations = 10\n",
    "verbose = True\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "query = \"What is 10+10?\"\n",
    "dict_inputs = {\"input\": query}\n",
    "limit = {\"recursion_limit\": iterations}\n",
    "\n",
    "# Execute the workflow and print state changes\n",
    "for event in workflow.stream(dict_inputs, config):\n",
    "    if verbose:\n",
    "        print(\"\\nEvent:\", event)\n",
    "    else:\n",
    "        print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
