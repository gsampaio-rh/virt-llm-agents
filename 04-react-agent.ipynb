{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a ReAct Agent with Tool Integration\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "In this notebook, you will learn how to build and deploy a ReAct (Reasoning + Acting) agent that can solve complex tasks by iteratively reasoning about the problem and invoking external tools. The agent will follow a structured **Thought → Action → Observation** loop to perform tasks, gather information, and provide answers. By the end of this notebook, you will understand how to:\n",
    "\n",
    "- Implement a ReAct agent that follows a structured reasoning process to break down user queries into smaller, solvable steps.\n",
    "- Integrate external tools (e.g., calculators, data retrieval functions) that the agent can use to perform actions as part of its reasoning process.\n",
    "- Manage tool outputs and errors efficiently, allowing the agent to adapt its reasoning based on real-time feedback from tool interactions.\n",
    "\n",
    "## Basic Concepts\n",
    "\n",
    "Before diving into the implementation, it’s important to understand the key concepts that form the foundation of a ReAct agent:\n",
    "\n",
    "- **ReAct Agent (Reasoning + Acting):** A specialized AI agent that alternates between reasoning about the task at hand and taking action using external tools. The agent follows a structured loop of **Thought → Action → Observation** until it has enough information to answer the query or decides that no further actions are needed.\n",
    "\n",
    "- **Thought → Action → Observation Loop:** The core of the ReAct agent's operation, where it reasons through the problem, chooses the appropriate tool or action to take, and then observes the results of the action to inform its next steps. This iterative process continues until a final answer is reached.\n",
    "\n",
    "- **Tool Integration:** Tools are external functions or APIs that the agent can call upon to perform specific actions, such as performing calculations or retrieving data. The agent dynamically selects which tools to use based on its reasoning.\n",
    "\n",
    "- **Error Handling and Feedback Loops:** The agent is designed to handle errors gracefully. When a tool fails or provides unexpected results, the agent adjusts its reasoning and continues processing. Proper error handling ensures the agent can complete tasks robustly.\n",
    "\n",
    "- **Prompt Engineering:** Crafting prompts that guide the ReAct agent's decision-making process. Well-designed prompts ensure the agent interacts with tools efficiently and effectively, adapting to the information it gathers.\n",
    "\n",
    "Understanding these concepts will give you the foundation needed to build a functional ReAct agent that can reason about tasks, perform actions with tools, and provide answers using structured outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "Before we begin, let's make sure your environment is set up correctly. We'll start by installing the necessary Python packages.\n",
    "\n",
    "### Installing Required Packages\n",
    "\n",
    "To get started, you'll need to install a few Python libraries. Run the following command to install them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in ./.conda/lib/python3.11/site-packages (0.2.16)\n",
      "Requirement already satisfied: langgraph in ./.conda/lib/python3.11/site-packages (0.2.16)\n",
      "Requirement already satisfied: langgraph-checkpoint-sqlite in ./.conda/lib/python3.11/site-packages (1.0.3)\n",
      "Requirement already satisfied: requests in ./.conda/lib/python3.11/site-packages (2.32.3)\n",
      "Requirement already satisfied: termcolor in ./.conda/lib/python3.11/site-packages (2.4.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.conda/lib/python3.11/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.conda/lib/python3.11/site-packages (from langchain) (2.0.34)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.conda/lib/python3.11/site-packages (from langchain) (3.10.5)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.38 in ./.conda/lib/python3.11/site-packages (from langchain) (0.2.38)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in ./.conda/lib/python3.11/site-packages (from langchain) (0.2.4)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in ./.conda/lib/python3.11/site-packages (from langchain) (0.1.110)\n",
      "Requirement already satisfied: numpy<2,>=1 in ./.conda/lib/python3.11/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in ./.conda/lib/python3.11/site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in ./.conda/lib/python3.11/site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<2.0.0,>=1.0.2 in ./.conda/lib/python3.11/site-packages (from langgraph) (1.0.8)\n",
      "Requirement already satisfied: aiosqlite<0.21.0,>=0.20.0 in ./.conda/lib/python3.11/site-packages (from langgraph-checkpoint-sqlite) (0.20.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.conda/lib/python3.11/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.conda/lib/python3.11/site-packages (from requests) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.conda/lib/python3.11/site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.conda/lib/python3.11/site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.8)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in ./.conda/lib/python3.11/site-packages (from aiosqlite<0.21.0,>=0.20.0->langgraph-checkpoint-sqlite) (4.12.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.conda/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.38->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./.conda/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.38->langchain) (24.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.conda/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.conda/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.conda/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./.conda/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
      "Requirement already satisfied: anyio in ./.conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.4.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./.conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\n",
      "Requirement already satisfied: sniffio in ./.conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.conda/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.conda/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.38->langchain) (3.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain langgraph langgraph-checkpoint-sqlite requests termcolor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building Blocks\n",
    "\n",
    "In this section, we'll start by building the basic components that our agent will use. These building blocks will form the foundation of our agent, enabling it to keep track of time, store data, and interact with a model.\n",
    "\n",
    "### Datetime Function\n",
    "\n",
    "The first building block we'll create is a simple function to get the current time. This is important because our agent might need to timestamp certain actions or events. Let's write a function that returns the current date and time in UTC format:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current UTC datetime: 2024-09-05 10:44:27.093422 \n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timezone\n",
    "\n",
    "\n",
    "def get_current_utc_datetime():\n",
    "    now_utc = datetime.now(timezone.utc)\n",
    "    return now_utc.strftime(\"%Y-%m-%d %H:%M:%S.%f UTC\")[:-3]\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "print(\"Current UTC datetime:\", get_current_utc_datetime())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Agent Data Handling\n",
    "Next, we'll introduce a simple way to handle data for our agent. In this case, we'll create a function that allows us to load and manage the agent's data. This data might include things like the agent's responsibilities, the tasks it needs to perform, and other relevant information.\n",
    "\n",
    "Let's assume the data is stored in a YAML file (a common format for configuration files), and we'll write a function to load this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded agent descriptions: {'agents': [{'name': 'Planner Agent', 'role': 'Planner Agent', 'responsibilities': ['Creates a comprehensive Migration Plan based on the tutorial.', 'Identifies key steps, target VMs, and source/target providers.', 'Coordinates and structures the plan for execution by other agents.']}, {'name': 'Project Manager (PM) Agent', 'role': 'Project Manager Agent', 'responsibilities': ['Manages the breakdown of tasks for the migration process.', 'Oversees task execution and ensures agents are working in coordination.', 'Ensures timelines are followed and adjusts the plan as necessary.', 'Communicates with all agents to ensure smooth task progression and resolve bottlenecks.']}, {'name': 'vSphere Engineer Agent', 'role': 'vSphere Engineer Agent', 'responsibilities': ['Handles VM identification and configuration within the vSphere environment.', 'Identifies VMs to migrate based on the tutorial instructions.', 'Manages and configures the Migration Toolkit for Virtualization (MTV) to set up the vSphere source providers.', 'Ensures proper VM resource allocation (CPU, memory, storage) within vSphere.', 'Powers off VMs and prepares them for migration if required.', 'Verifies that the VMs in the vSphere environment are ready for migration.']}, {'name': 'OpenShift Engineer Agent', 'role': 'OpenShift Engineer Agent', 'responsibilities': ['Sets up and configures the OpenShift environment for the migrated VMs.', 'Ensures that required OpenShift projects (namespaces) are created and accessible.', 'Configures the Migration Toolkit for Virtualization (MTV) to set up OpenShift as the target provider.', 'Deploys and configures the migrated VMs in OpenShift, ensuring proper integration with storage, networking, and compute resources.', 'Verifies that the OpenShift environment is correctly configured and ready to host migrated VMs.', 'Provides troubleshooting and remediation if issues arise during the setup.', 'Coordinates with the Networking Agent to ensure OpenShift routes, services, and load balancers are configured for migrated applications.']}, {'name': 'Reviewer Agent', 'role': 'Reviewer Agent', 'responsibilities': ['Validates the successful migration of VMs to the target environment.', 'Ensures the application and VMs are functioning correctly post-migration.', 'Checks logs, network settings, and storage allocations for correctness.', 'Provides a final report on the migration’s success.']}]}\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from typing import Dict, Any\n",
    "\n",
    "\n",
    "def load_agent_descriptions(description_file: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Load the agent descriptions from a YAML file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(description_file, \"r\") as file:\n",
    "            return yaml.safe_load(file)\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"Description file '{description_file}' not found.\")\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "agents_description = load_agent_descriptions(\"agents.yaml\")\n",
    "print(\"Loaded agent descriptions:\", agents_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuring a Simple Model\n",
    "Now that we have the basic building blocks, we'll move on to configuring a model that our agent can use to perform its tasks. This model will process inputs (like a user request) and generate outputs (like a task list).\n",
    "\n",
    "### Model Configuration\n",
    "We'll start by setting up a simple configuration for the model. This configuration will include details like the model's endpoint, temperature, and other parameters. Let's create a function to handle this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model configuration: {'model_endpoint': 'http://localhost:11434/api/generate', 'model': 'llama3:instruct', 'temperature': 0.0, 'top_p': 1.0, 'top_k': 0, 'repetition_penalty': 1.0, 'headers': {'Content-Type': 'application/json'}, 'stop': None}\n"
     ]
    }
   ],
   "source": [
    "def setup_ollama_model(\n",
    "    model, temperature=0.0, top_p=1.0, top_k=0, repetition_penalty=1.0, stop=None\n",
    "):\n",
    "    return {\n",
    "        \"model_endpoint\": \"http://localhost:11434/api/generate\",\n",
    "        \"model\": model,\n",
    "        \"temperature\": temperature,\n",
    "        \"top_p\": top_p,\n",
    "        \"top_k\": top_k,\n",
    "        \"repetition_penalty\": repetition_penalty,\n",
    "        \"headers\": {\"Content-Type\": \"application/json\"},\n",
    "        \"stop\": stop,\n",
    "    }\n",
    "\n",
    "\n",
    "# Example configuration:\n",
    "ollama_config = setup_ollama_model(model=\"llama3:instruct\")\n",
    "print(\"Model configuration:\", ollama_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function returns a dictionary with the model's configuration. You can adjust the parameters based on the specific model you're using or the task requirements.\n",
    "\n",
    "### Preparing a Request\n",
    "With the model configured, the next step is to prepare a request that the agent can send to the model. This request will include the user's input, the system's instructions, and any other necessary information. Let's write a function to prepare this request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_payload(\n",
    "    user_prompt: str,\n",
    "    sys_prompt: str,\n",
    "    stream: bool = False,\n",
    "    config: Dict[str, Any] = ollama_config,\n",
    ") -> Dict[str, Any]:\n",
    "    return {\n",
    "        \"model\": config.get(\"model\"),\n",
    "        \"format\": \"json\",\n",
    "        \"prompt\": user_prompt,\n",
    "        \"system\": sys_prompt,\n",
    "        \"stream\": stream,\n",
    "        \"temperature\": config.get(\"temperature\", 0.0),\n",
    "        \"top_p\": config.get(\"top_p\", 1.0),\n",
    "        \"top_k\": config.get(\"top_k\", 0),\n",
    "        \"repetition_penalty\": config.get(\"repetition_penalty\", 1.0),\n",
    "        \"stop\": config.get(\"stop\"),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sending a Request\n",
    "We'll start by writing a function to send the request to the model's endpoint and receive a response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "def request_model_generate_endpoint(\n",
    "    payload: Dict[str, Any], config: Dict[str, Any] = ollama_config\n",
    ") -> Dict[str, Any]:\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            config.get(\"model_endpoint\"),\n",
    "            headers=config.get(\"headers\", {\"Content-Type\": \"application/json\"}),\n",
    "            data=json.dumps(payload),\n",
    "            timeout=30,\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "\n",
    "        if response.content.strip():\n",
    "            return response.json()\n",
    "        else:\n",
    "            return {\"error\": \"Empty response from model\"}\n",
    "\n",
    "    except requests.RequestException as e:\n",
    "        raise Exception(f\"Request failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function sends the prepared payload to the model's endpoint using the `requests` library. It then checks if the response is valid and returns the content. If there's an error in the request, it raises an exception with a descriptive message.\n",
    "\n",
    "### Processing the Response\n",
    "Finally, we'll write a function to process and understand the model's response. This might involve formatting the response or extracting specific information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_model_response(response_json: Dict[str, Any]) -> str:\n",
    "    try:\n",
    "        response_content = json.loads(response_json.get(\"response\", \"{}\"))\n",
    "        pretty_content = json.dumps(response_content, indent=4)\n",
    "\n",
    "        return pretty_content\n",
    "    except json.JSONDecodeError:\n",
    "        return \"Error processing the response\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Custom Tools\n",
    "\n",
    "In this section, we demonstrate how to integrate custom tools into the ReAct agent's workflow. These tools allow the agent to perform specific actions based on the task requirements. We'll start with a basic calculator tool that can perform fundamental arithmetic operations.\n",
    "\n",
    "### Basic Calculator Tool\n",
    "\n",
    "The `basic_calculator` tool performs basic arithmetic operations like addition, subtraction, multiplication, and division. The tool accepts two numbers and an operation as input and returns the result.\n",
    "\n",
    "#### Supported Operations:\n",
    "- `add`: Adds two numbers.\n",
    "- `subtract`: Subtracts the second number from the first.\n",
    "- `multiply`: Multiplies two numbers.\n",
    "- `divide`: Divides the first number by the second (raises an exception for division by zero).\n",
    "- `modulus`: Finds the remainder when the first number is divided by the second.\n",
    "- `power`: Raises the first number to the power of the second.\n",
    "- Comparison operators: `lt` (less than), `le` (less than or equal to), `eq` (equal to), `ne` (not equal to), `ge` (greater than or equal to), `gt` (greater than).\n",
    "\n",
    "The agent will invoke this tool based on the reasoning process and provide structured input in the form of JSON. Let's take a look at the implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from langchain.tools import tool\n",
    "\n",
    "\n",
    "@tool(parse_docstring=True)\n",
    "def basic_calculator(num1, num2, operation):\n",
    "    \"\"\"\n",
    "    Perform a numeric operation on two numbers based on the input string.\n",
    "\n",
    "    Parameters:\n",
    "    'num1' (int): The first number.\n",
    "    'num2' (int): The second number.\n",
    "    'operation' (str): The operation to perform. Supported operations are 'add', 'subtract',\n",
    "                        'multiply', 'divide', 'floor_divide', 'modulus', 'power', 'lt',\n",
    "                        'le', 'eq', 'ne', 'ge', 'gt'.\n",
    "\n",
    "    Returns:\n",
    "    str: The formatted result of the operation.\n",
    "\n",
    "    Raises:\n",
    "    Exception: If an error occurs during the operation (e.g., division by zero).\n",
    "    ValueError: If an unsupported operation is requested or input is invalid.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the supported operations\n",
    "    operations = {\n",
    "        \"add\": operator.add,\n",
    "        \"subtract\": operator.sub,\n",
    "        \"multiply\": operator.mul,\n",
    "        \"divide\": operator.truediv,\n",
    "        \"floor_divide\": operator.floordiv,\n",
    "        \"modulus\": operator.mod,\n",
    "        \"power\": operator.pow,\n",
    "        \"lt\": operator.lt,\n",
    "        \"le\": operator.le,\n",
    "        \"eq\": operator.eq,\n",
    "        \"ne\": operator.ne,\n",
    "        \"ge\": operator.ge,\n",
    "        \"gt\": operator.gt,\n",
    "    }\n",
    "\n",
    "    # Check if the operation is supported\n",
    "    if operation in operations:\n",
    "        try:\n",
    "            # Perform the operation\n",
    "            result = operations[operation](num1, num2)\n",
    "            result_formatted = (\n",
    "                f\"\\n\\nThe answer is: {result}.\\nCalculated with basic_calculator.\"\n",
    "            )\n",
    "            return result_formatted\n",
    "        except Exception as e:\n",
    "            return str(e), \"\\n\\nError during operation execution.\"\n",
    "    else:\n",
    "        return \"\\n\\nUnsupported operation. Please provide a valid operation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"basic_calculator(num1, num2, operation) - Perform a numeric operation on two numbers based on the input string. Parameters:\\n'num1' (int): The first number.\\n'num2' (int): The second number.\\n'operation' (str): The operation to perform. Supported operations are 'add', 'subtract',\\n                    'multiply', 'divide', 'floor_divide', 'modulus', 'power', 'lt',\\n                    'le', 'eq', 'ne', 'ge', 'gt'., args: {{'num1': {{'title': 'Num1'}}, 'num2': {{'title': 'Num2'}}, 'operation': {{'title': 'Operation'}}}}\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools.render import render_text_description_and_args\n",
    "\n",
    "# To use these tools within our agent, we register them in a list. This list will be referenced by the agent to determine which tools are available for use.\n",
    "tools = [basic_calculator]\n",
    "tools_description = (\n",
    "    render_text_description_and_args(tools).replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    ")\n",
    "\n",
    "tools_description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. State Management\n",
    "\n",
    "State management is an essential concept when working with agents. The \"state\" of an agent refers to its current condition or the information it has at any given time. For instance, if an agent is working through a list of tasks, its state might include which tasks have been completed, which are in progress, and which are yet to be started.\n",
    "\n",
    "Managing this state is crucial because it allows the agent to keep track of what it has done and what it needs to do next. Without proper state management, an agent might lose track of its progress, repeat tasks, or skip important steps. In this notebook, you'll learn how to manage an agent's state effectively, ensuring that it operates smoothly and efficiently.\n",
    "\n",
    "### Implementation of State Management\n",
    "\n",
    "To implement state management for our ReAct agent, we define a structured data model (`AgentGraphState`) that holds all the relevant information the agent needs to function effectively. This model includes:\n",
    "- **Input:** The current command or task that the agent is working on.\n",
    "- **Response:** The outputs or actions the agent has generated.\n",
    "\n",
    "Additionally, we provide a utility function, `update_state`, which allows for updating specific elements of the agent's state. This function ensures that the state is consistently and accurately maintained, which is critical for the agent to operate effectively. By checking for the existence of keys before updating, the function helps prevent errors and maintains the integrity of the state.\n",
    "\n",
    "Together, these components form the backbone of the agent's state management system, enabling it to manage complex workflows and adapt to changes dynamically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph.message import add_messages\n",
    "from typing import Annotated, TypedDict, Any\n",
    "\n",
    "class AgentGraphState(TypedDict):\n",
    "    input: str\n",
    "    response: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "def update_state(state: AgentGraphState, key: str, value: Any):\n",
    "    \"\"\"\n",
    "    Update the state of the agent. Warn if the key doesn't exist.\n",
    "    \"\"\"\n",
    "    if key in state:\n",
    "        state[key] = value\n",
    "    else:\n",
    "        print(f\"Warning: Attempting to update a non-existing state key '{key}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. What is a ReAct Agent?\n",
    "\n",
    "A **ReAct agent** is a specialized type of intelligent agent designed to reason about a task, take appropriate actions, and adapt based on the outcomes of those actions. The term **ReAct** stands for **Reasoning + Acting**, which reflects how the agent alternates between thinking through a problem and interacting with tools or external systems to achieve the desired result.\n",
    "\n",
    "In simple terms, a ReAct agent doesn't just follow a fixed set of instructions blindly; it thinks through each step, decides what actions to take, and adjusts its course as needed. For example, if the agent is tasked with solving a math problem, it will first reason about the best approach (e.g., using a calculator tool), perform the calculation, and then analyze the result to decide the next steps.\n",
    "\n",
    "### How Does a ReAct Agent Work?\n",
    "\n",
    "A ReAct agent follows a cycle known as the **Thought → Action → Observation** loop:\n",
    "1. **Thought**: The agent reasons about the task, breaks it down into smaller, manageable parts, and decides which action or tool to use next.\n",
    "2. **Action**: The agent executes the chosen action, such as invoking a tool to perform a calculation or retrieve information.\n",
    "3. **Observation**: After the action is completed, the agent observes the result, evaluates if more steps are necessary, and then returns to the reasoning stage if needed.\n",
    "\n",
    "This cycle repeats until the agent has gathered enough information to provide a complete answer or complete the task.\n",
    "\n",
    "### Why Use a ReAct Agent?\n",
    "\n",
    "The primary benefit of a ReAct agent is its ability to autonomously solve complex problems through a process of reasoning and interaction. Unlike simple agents that just follow pre-defined rules, a ReAct agent can:\n",
    "- **Reason through multi-step tasks**: It can break down complex queries into smaller steps and handle them one by one.\n",
    "- **Adapt to new information**: Based on the outcome of each action, the agent can modify its approach and try different strategies if needed.\n",
    "- **Perform external actions**: ReAct agents can interact with tools, APIs, and systems to gather data, perform calculations, or execute external processes.\n",
    "\n",
    "For example, in the context of our notebook, the ReAct agent uses tools like the `basic_calculator` to perform mathematical operations. The agent reasons about when to use the tool, performs the operation, and observes the result to determine if more actions are needed before completing the task.\n",
    "\n",
    "In summary, a ReAct agent is a versatile, intelligent system capable of reasoning, acting, and learning from its actions to accomplish tasks autonomously, making it highly effective for problem-solving in dynamic environments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Prompt\n",
    "\n",
    "The system prompt provides the instructions that guide the agent in reasoning through tasks, using tools, and generating structured responses. It sets the context in which the agent operates, including its environment and knowledge limits, so the agent knows up to which point its information is accurate (in this case, until December 2023).\n",
    "\n",
    "The prompt also tells the agent how to use tools to complete tasks. The agent is responsible for deciding which tool to use and in what order, depending on the problem it is trying to solve. When using tools, the agent needs to follow a specific JSON format for both inputs and outputs, making sure that all interactions are clear and structured.\n",
    "\n",
    "The agent repeats a cycle of **thought → action → observation**: first, it thinks about the task and decides what action to take, then it uses a tool to perform the action, and finally, it observes the result. This cycle continues until the agent has enough information to answer the user’s question. If the agent receives a clear answer from the tool, it will stop further actions and give the final result. Otherwise, it will explain why it couldn’t complete the task and suggest adjustments or corrections if needed.\n",
    "\n",
    "The main goal of the system prompt is to ensure the agent acts logically, uses tools effectively, and provides results in a structured and consistent way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SYS_REACT_PROMPT = \"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "Environment: ipython  \n",
    "Knowledge Cutoff Date: December 2023  \n",
    "Current Date: {datetime}\n",
    "\n",
    "You are an intelligent assistant designed to handle various tasks, including answering questions, providing summaries, and performing detailed analyses. All outputs must strictly be in JSON format.\n",
    "\n",
    "---\n",
    "\n",
    "## Tools\n",
    "You have access to a variety of tools to assist in completing tasks. You are responsible for determining the appropriate sequence of tool usage to break down complex tasks into subtasks when necessary.\n",
    "\n",
    "The available tools include:\n",
    "\n",
    "{tools_description}\n",
    "\n",
    "---\n",
    "\n",
    "## Output Format:\n",
    "To complete the task, please use the following format:\n",
    "\n",
    "{{\n",
    "  \"thought\": \"Describe your thought process here, including why a tool may be necessary to proceed.\",\n",
    "  \"action\": \"Specify the tool you want to use.\",\n",
    "  \"action_input\": {{ # Provide valid JSON input for the action, ensuring it matches the tool’s expected format and data types.\n",
    "    \"key\": \"Value inputs to the tool in valid JSON format.\"\n",
    "  }}\n",
    "}}\n",
    "\n",
    "After performing an action, the tool will provide a response in the following format:\n",
    "\n",
    "{{\n",
    "  \"observation\": \"The result of the tool invocation\",\n",
    "}}\n",
    "\n",
    "You should keep repeating the format (thought → action → observation) until you have gathered enough information to answer the question. **If the observation provides a clear and complete answer to the user's query, immediately conclude with the final answer and do not perform further actions.** Once you have sufficient information, respond using one of the following formats:\n",
    "\n",
    "\n",
    "If the tool result is successful and the task is complete:\n",
    "\n",
    "{{\n",
    "  \"thought\": \"The tool '{{action}}' executed successfully, and the output meets the acceptance criteria. No further actions are required.\",\n",
    "  \"final_answer\": \"The task has been completed successfully with the tool output: {{tool_result}}.\"\n",
    "}}\n",
    "\n",
    "Or, if you cannot answer:\n",
    "\n",
    "{{\n",
    "  \"thought\": \"The tool '{{action}}' failed to execute successfully. The error was: {{tool_result}}. Here is what went wrong and what needs to be corrected: [Provide corrections or adjustments].\",\n",
    "  \"action_correction\": \"Description of what needs to be adjusted or corrected before retrying.\"\n",
    "}}\n",
    "\n",
    "---\n",
    "\n",
    "### Remember:\n",
    "- Use the tools effectively and ensure inputs match the required format exactly as described in the task.\n",
    "- **If a tool provides a complete and clear answer, do not continue invoking further tools.**\n",
    "- Maintain the JSON format and ensure all fields are filled out correctly.\n",
    "- Do not include additional metadata such as `title`, `description`, or `type` in the `tool_input`.\n",
    "\n",
    "---\n",
    "\n",
    "## Current Conversation\n",
    "Below is the ongoing conversation consisting of interleaving human and assistant messages:\n",
    "\n",
    "{agent_scratchpad}\n",
    "<|eot_id|>\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_react_prompt(\n",
    "    agent_scratchpad: str = \"\",\n",
    "    tools_description: str = tools_description,\n",
    ") -> str:\n",
    "    return DEFAULT_SYS_REACT_PROMPT.format(\n",
    "        agent_scratchpad=agent_scratchpad,\n",
    "        tools_description=tools_description,\n",
    "        datetime=get_current_utc_datetime(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared payload: {'model': 'llama3:instruct', 'format': 'json', 'prompt': 'What tasks should I complete in order to make pasta?', 'system': '\\n<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nEnvironment: ipython  \\nKnowledge Cutoff Date: December 2023  \\nCurrent Date: 2024-09-05 10:44:27.214276 \\n\\nYou are an intelligent assistant designed to handle various tasks, including answering questions, providing summaries, and performing detailed analyses. All outputs must strictly be in JSON format.\\n\\n---\\n\\n## Tools\\nYou have access to a variety of tools to assist in completing tasks. You are responsible for determining the appropriate sequence of tool usage to break down complex tasks into subtasks when necessary.\\n\\nThe available tools include:\\n\\nbasic_calculator(num1, num2, operation) - Perform a numeric operation on two numbers based on the input string. Parameters:\\n\\'num1\\' (int): The first number.\\n\\'num2\\' (int): The second number.\\n\\'operation\\' (str): The operation to perform. Supported operations are \\'add\\', \\'subtract\\',\\n                    \\'multiply\\', \\'divide\\', \\'floor_divide\\', \\'modulus\\', \\'power\\', \\'lt\\',\\n                    \\'le\\', \\'eq\\', \\'ne\\', \\'ge\\', \\'gt\\'., args: {{\\'num1\\': {{\\'title\\': \\'Num1\\'}}, \\'num2\\': {{\\'title\\': \\'Num2\\'}}, \\'operation\\': {{\\'title\\': \\'Operation\\'}}}}\\n\\n---\\n\\n## Output Format:\\nTo complete the task, please use the following format:\\n\\n{\\n  \"thought\": \"Describe your thought process here, including why a tool may be necessary to proceed.\",\\n  \"action\": \"Specify the tool you want to use.\",\\n  \"action_input\": { # Provide valid JSON input for the action, ensuring it matches the tool’s expected format and data types.\\n    \"key\": \"Value inputs to the tool in valid JSON format.\"\\n  }\\n}\\n\\nAfter performing an action, the tool will provide a response in the following format:\\n\\n{\\n  \"observation\": \"The result of the tool invocation\",\\n}\\n\\nYou should keep repeating the format (thought → action → observation) until you have gathered enough information to answer the question. **If the observation provides a clear and complete answer to the user\\'s query, immediately conclude with the final answer and do not perform further actions.** Once you have sufficient information, respond using one of the following formats:\\n\\n\\nIf the tool result is successful and the task is complete:\\n\\n{\\n  \"thought\": \"The tool \\'{action}\\' executed successfully, and the output meets the acceptance criteria. No further actions are required.\",\\n  \"final_answer\": \"The task has been completed successfully with the tool output: {tool_result}.\"\\n}\\n\\nOr, if you cannot answer:\\n\\n{\\n  \"thought\": \"The tool \\'{action}\\' failed to execute successfully. The error was: {tool_result}. Here is what went wrong and what needs to be corrected: [Provide corrections or adjustments].\",\\n  \"action_correction\": \"Description of what needs to be adjusted or corrected before retrying.\"\\n}\\n\\n---\\n\\n### Remember:\\n- Use the tools effectively and ensure inputs match the required format exactly as described in the task.\\n- **If a tool provides a complete and clear answer, do not continue invoking further tools.**\\n- Maintain the JSON format and ensure all fields are filled out correctly.\\n- Do not include additional metadata such as `title`, `description`, or `type` in the `tool_input`.\\n\\n---\\n\\n## Current Conversation\\nBelow is the ongoing conversation consisting of interleaving human and assistant messages:\\n\\n\\n<|eot_id|>\\n<|start_header_id|>user<|end_header_id|>\\n', 'stream': False, 'temperature': 0.0, 'top_p': 1.0, 'top_k': 0, 'repetition_penalty': 1.0, 'stop': None}\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "payload = prepare_payload(\n",
    "    user_prompt=\"What tasks should I complete in order to make pasta?\",\n",
    "    sys_prompt=write_react_prompt(),\n",
    ")\n",
    "print(\"Prepared payload:\", payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Implementing the Agent\n",
    "\n",
    "### Creating a Simple Agent Class\n",
    "\n",
    "In this step, we define the `Agent` class, which is responsible for managing the state of the PM agent, interacting with the model, and processing the responses. This class encapsulates the core functionalities needed to execute tasks autonomously.\n",
    "\n",
    "### Key Components:\n",
    "- **Initialization (`__init__`)**: The constructor initializes the agent with its state, role, and model configuration. This setup is crucial for ensuring that the agent operates within the defined parameters and context.\n",
    "  \n",
    "- **Model Invocation (`invoke_model`)**: This method prepares the input payload, sends it to the model for processing, and handles the model's response. It's where the agent interacts with the LLM, using the system prompt and user prompt to generate meaningful outputs.\n",
    "\n",
    "- **Task Execution (`execute_task`)**: This method allows the agent to execute a specific task based on a user request. It utilizes the system prompt tailored for the task and processes the response generated by the model.\n",
    "\n",
    "The `Agent` class is fundamental in making our PM agent autonomous, enabling it to perform its duties without constant human oversight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages.ai import AIMessage\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.messages import HumanMessage\n",
    "from termcolor import colored\n",
    "\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, state: AgentGraphState, role: str, model_config: dict):\n",
    "        \"\"\"\n",
    "        Initialize the Agent with a state, role, and model configuration.\n",
    "        \"\"\"\n",
    "        self.state = state\n",
    "        self.role = role\n",
    "        self.model_config = model_config\n",
    "\n",
    "    def invoke_model(self, sys_prompt: str, user_prompt: str):\n",
    "        \"\"\"\n",
    "        Prepare the payload, send the request to the model, and process the response.\n",
    "        \"\"\"\n",
    "        # Prepare the payload\n",
    "        payload = prepare_payload(user_prompt, sys_prompt, config=self.model_config)\n",
    "\n",
    "        # Invoke the model and get the response\n",
    "        response_json = request_model_generate_endpoint(\n",
    "            payload, config=self.model_config\n",
    "        )\n",
    "\n",
    "        # Process the model's response\n",
    "        response_content = process_model_response(response_json)\n",
    "\n",
    "        # Return the processed response\n",
    "        return response_content\n",
    "\n",
    "    def react(self, user_request: str) -> dict:\n",
    "        \"\"\"\n",
    "        Execute the task based on the user's request by following the thought → action → observation loop.\n",
    "        \"\"\"\n",
    "        sys_prompt = write_react_prompt()\n",
    "        final_answer = None\n",
    "\n",
    "        # Start with the user's request as the first input\n",
    "        user_prompt = user_request\n",
    "        action = None\n",
    "        action_input = None\n",
    "        scratchpad = []\n",
    "\n",
    "        human_message = HumanMessage(content=user_prompt)\n",
    "        print(colored(human_message.pretty_repr(), \"green\"))\n",
    "\n",
    "        # Loop until a final answer is generated\n",
    "        while final_answer is None:\n",
    "            # Invoke the model with the system prompt and current user input\n",
    "\n",
    "            response = self.invoke_model(sys_prompt=sys_prompt, user_prompt=user_prompt)\n",
    "\n",
    "            try:\n",
    "                # Parse the response assuming it's in JSON format\n",
    "                response_dict = json.loads(response)  # Assuming response is a JSON object\n",
    "\n",
    "                ai_message = AIMessage(content=response)\n",
    "                print(colored(ai_message.pretty_repr(), \"cyan\"))\n",
    "\n",
    "                scratchpad.append(ai_message)\n",
    "\n",
    "                action = response_dict.get(\"action\", None)\n",
    "                action_input = response_dict.get(\"action_input\", None)\n",
    "\n",
    "                # If there is an action, execute the corresponding tool\n",
    "                if action and action_input:\n",
    "                    status, tool_response = self.execute_tool(action, action_input)\n",
    "\n",
    "                    # Formulate the observation to feed back into the model\n",
    "                    tool_response_dict = {\n",
    "                        \"observation\": tool_response,\n",
    "                    }\n",
    "\n",
    "                    tool_response_json = json.dumps(tool_response_dict, indent=4)\n",
    "\n",
    "                    tool_system_message = SystemMessage(content=tool_response_json)\n",
    "                    print(colored(tool_system_message.pretty_repr(), \"yellow\"))\n",
    "\n",
    "                    user_prompt = tool_response_json\n",
    "\n",
    "                # Check if the model has given a final answer\n",
    "                if \"final_answer\" in response_dict:\n",
    "                    final_answer = response_dict[\"final_answer\"]\n",
    "\n",
    "            except Exception as e:\n",
    "                print(str(e))\n",
    "                error_message = SystemMessage(content=str(e))\n",
    "                scratchpad.append(error_message)\n",
    "\n",
    "        # Return the final answer\n",
    "        return {\"response\": AIMessage(content=final_answer)}\n",
    "\n",
    "    def execute_tool(self, action: str, action_input: dict):\n",
    "        \"\"\"\n",
    "        Simulate the tool execution based on the action and action_input.\n",
    "        In a real-world scenario, this would call the appropriate tool.\n",
    "        \"\"\"\n",
    "        # Simulate some tool actions (this would be replaced by actual tool logic)\n",
    "        print(\n",
    "            colored(\n",
    "                \"================================ Calling Tool ================================\",\n",
    "                \"magenta\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "        print(colored(f\"Tool: {action}\", \"magenta\"))\n",
    "        print(colored(f\"Tool Input: {action_input}\", \"magenta\"))\n",
    "\n",
    "        for tool in tools:\n",
    "            if tool.name == action:\n",
    "                try:\n",
    "                    result = tool.invoke(action_input)\n",
    "                    print(colored(f\"Tool Result: {result}\", \"magenta\"))\n",
    "                    return True, result\n",
    "                except Exception as e:\n",
    "                    return False, f\"Error executing tool {action}: {str(e)}\"\n",
    "        else:\n",
    "            return f\"Tool {action} not found or unsupported operation.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Creating and Compiling the Workflow Graph\n",
    "\n",
    "### Constructing the PM Agent's Workflow\n",
    "\n",
    "In this step, we build the workflow graph that represents the PM agent's process. This graph outlines the sequence of operations, including task execution, validation, and decision-making.\n",
    "\n",
    "### Key Components:\n",
    "- **Node Definitions**: Each node in the graph represents a step in the workflow, such as invoking the PM agent or validating the output.\n",
    "  \n",
    "- **Edge Definitions**: Edges define the flow between nodes, determining how the agent progresses through the tasks and validation steps.\n",
    "\n",
    "- **Workflow Compilation**: Once the graph is defined, it is compiled into a workflow that can be executed. This compiled workflow represents the full sequence of operations that the PM agent will follow to manage the VM migration.\n",
    "\n",
    "By constructing and compiling this workflow graph, we ensure that the PM agent operates in a structured and efficient manner, handling tasks and making decisions in a logical sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def react_node_function(state: AgentGraphState):\n",
    "    react_agent = Agent(\n",
    "        state=state,\n",
    "        role=\"REACT_AGENT\",\n",
    "        model_config=ollama_config,\n",
    "    )\n",
    "\n",
    "    return react_agent.react(user_request=state[\"input\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "\n",
    "def create_graph() -> StateGraph:\n",
    "    \"\"\"\n",
    "    Create the state graph by defining nodes and edges.\n",
    "\n",
    "    Returns:\n",
    "    - StateGraph: The compiled state graph ready for execution.\n",
    "    \"\"\"\n",
    "    graph = StateGraph(AgentGraphState)\n",
    "\n",
    "    # Add nodes\n",
    "    graph.add_node(\"react_agent\", react_node_function)\n",
    "\n",
    "    # Define the flow of the graph\n",
    "    graph.add_edge(START, \"react_agent\")\n",
    "    graph.add_edge(\"react_agent\", END)\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Sqlite Persistence for Graph State\n",
    "\n",
    "In this cell, we define and use a method to initialize an `SqliteSaver` instance from the `langgraph.checkpoint.sqlite` module. The `SqliteSaver` class allows the graph state to be persisted in an SQLite database, which is more durable and suitable for applications requiring longer-term storage compared to an in-memory solution.\n",
    "\n",
    "The `from_conn_stringx` method is defined as a class method that takes a connection string as input, creates a connection to the SQLite database using `sqlite3.connect`, and then returns an `SqliteSaver` instance using this connection. This method simplifies the creation of an `SqliteSaver` instance directly from a connection string.\n",
    "\n",
    "This approach is particularly useful for ensuring that the state of the `StateGraph` is saved to a local or memory-based SQLite database, enabling the retention of context across multiple interactions in AI-driven applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "def from_conn_stringx(\n",
    "    cls,\n",
    "    conn_string: str,\n",
    ") -> \"SqliteSaver\":\n",
    "    return SqliteSaver(conn=sqlite3.connect(conn_string, check_same_thread=False))\n",
    "\n",
    "\n",
    "SqliteSaver.from_conn_stringx = classmethod(from_conn_stringx)\n",
    "\n",
    "memory = SqliteSaver.from_conn_stringx(\":memory:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Executing the Workflow\n",
    "\n",
    "With the workflow graph compiled, the final step is to execute the workflow. This involves providing the agent with an input query, such as a request to generate a VM migration plan, and allowing the workflow to run through its defined sequence.\n",
    "\n",
    "### Creating and Running the Workflow\n",
    "\n",
    "In this step, we create and execute the PM agent's workflow to process a set of tasks.\n",
    "\n",
    "- **Graph Creation**: \n",
    "  - We first create the workflow graph using `create_graph()` and compile it with a memory-based checkpoint.\n",
    "  - The compiled workflow will manage the task execution, validation, and feedback handling.\n",
    "\n",
    "- **Workflow Parameters**:\n",
    "  - We define the number of iterations (`iterations = 10`), set verbose mode to `True`, and configure the thread ID.\n",
    "  - A query containing three tasks (VM details retrieval, migration plan creation, and migration start) is provided as input.\n",
    "\n",
    "- **Workflow Execution**:\n",
    "  - The workflow is executed using `workflow.stream()`, and it processes each task sequentially.\n",
    "  - Depending on the state of the workflow, feedback or task responses are printed to track progress.\n",
    "\n",
    "This step runs the agent through the defined tasks and prints the state changes for each event in the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph and workflow created.\n",
      "\u001b[32m================================ Human Message =================================\n",
      "\n",
      "What is 10+10?\u001b[0m\n",
      "\u001b[36m================================== Ai Message ==================================\n",
      "\n",
      "{\n",
      "    \"thought\": \"To answer this question, I can use the 'basic_calculator' tool to perform a simple arithmetic operation.\",\n",
      "    \"action\": \"basic_calculator\",\n",
      "    \"action_input\": {\n",
      "        \"num1\": 10,\n",
      "        \"num2\": 10,\n",
      "        \"operation\": \"add\"\n",
      "    }\n",
      "}\u001b[0m\n",
      "\u001b[35m================================ Calling Tool ================================\u001b[0m\n",
      "\u001b[35mTool: basic_calculator\u001b[0m\n",
      "\u001b[35mTool Input: {'num1': 10, 'num2': 10, 'operation': 'add'}\u001b[0m\n",
      "\u001b[35mTool Result: \n",
      "\n",
      "The answer is: 20.\n",
      "Calculated with basic_calculator.\u001b[0m\n",
      "\u001b[33m================================ System Message ================================\n",
      "\n",
      "{\n",
      "    \"observation\": \"\\n\\nThe answer is: 20.\\nCalculated with basic_calculator.\"\n",
      "}\u001b[0m\n",
      "\u001b[36m================================== Ai Message ==================================\n",
      "\n",
      "{\n",
      "    \"thought\": \"It seems like the user has provided an observation about the result of using the `basic_calculator` tool.\",\n",
      "    \"action\": \"No further action required, as the task appears to be complete based on the provided observation. The assistant can conclude that the answer is indeed 20.\"\n",
      "}\u001b[0m\n",
      "\u001b[36m================================== Ai Message ==================================\n",
      "\n",
      "{\n",
      "    \"thought\": \"The tool 'basic_calculator' executed successfully, and the output meets the acceptance criteria. No further actions are required.\",\n",
      "    \"final_answer\": \"The task has been completed successfully with the tool output: \\u202a20.\\u202c\"\n",
      "}\u001b[0m\n",
      "\n",
      "Event: {'react_agent': {'response': AIMessage(content='The task has been completed successfully with the tool output: \\u202a20.\\u202c')}}\n"
     ]
    }
   ],
   "source": [
    "# Create the graph and compile the workflow\n",
    "graph = create_graph()\n",
    "workflow = graph.compile(checkpointer=memory)\n",
    "print(\"Graph and workflow created.\")\n",
    "\n",
    "# Define workflow parameters\n",
    "iterations = 10\n",
    "verbose = True\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "query = \"What is 10+10?\"\n",
    "dict_inputs = {\"input\": query}\n",
    "limit = {\"recursion_limit\": iterations}\n",
    "\n",
    "# Execute the workflow and print state changes\n",
    "for event in workflow.stream(dict_inputs, config):\n",
    "    if verbose:\n",
    "            print(\"\\nEvent:\", event)\n",
    "    else:\n",
    "        print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
