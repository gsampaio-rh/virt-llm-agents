{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenShift Workflow Agent\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates how to build an AI-powered workflow agent that interacts with **OpenShift**, retrieves details about various resources (such as pods or virtual machines), and processes commands using a machine learning model. The agent also integrates with custom tools and persists workflow data using **SQLite**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "### Installing Required Packages\n",
    "\n",
    "Before we begin, we need to install several Python libraries that are critical for this workflow. These libraries will allow us to:\n",
    "\n",
    "- **`langchain`**: A framework for building language models and agents.\n",
    "- **`langgraph`**: A library for creating AI-driven workflows.\n",
    "- **`requests`**: For sending HTTP requests.\n",
    "- **`python-dotenv`**: For managing environment variables securely.\n",
    "- **`kubernetes`**: For interacting with the OpenShift API.\n",
    "\n",
    "We use the `%pip install` command to ensure all necessary packages are installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in ./.conda/lib/python3.11/site-packages (0.2.16)\n",
      "Requirement already satisfied: langgraph in ./.conda/lib/python3.11/site-packages (0.2.16)\n",
      "Requirement already satisfied: langgraph-checkpoint-sqlite in ./.conda/lib/python3.11/site-packages (1.0.3)\n",
      "Requirement already satisfied: requests in ./.conda/lib/python3.11/site-packages (2.32.3)\n",
      "Requirement already satisfied: termcolor in ./.conda/lib/python3.11/site-packages (2.4.0)\n",
      "Requirement already satisfied: aiohttp in ./.conda/lib/python3.11/site-packages (3.10.5)\n",
      "Requirement already satisfied: python-dotenv in ./.conda/lib/python3.11/site-packages (1.0.1)\n",
      "Requirement already satisfied: kubernetes in ./.conda/lib/python3.11/site-packages (30.1.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.conda/lib/python3.11/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.conda/lib/python3.11/site-packages (from langchain) (2.0.34)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.38 in ./.conda/lib/python3.11/site-packages (from langchain) (0.2.38)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in ./.conda/lib/python3.11/site-packages (from langchain) (0.2.4)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in ./.conda/lib/python3.11/site-packages (from langchain) (0.1.110)\n",
      "Requirement already satisfied: numpy<2,>=1 in ./.conda/lib/python3.11/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in ./.conda/lib/python3.11/site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in ./.conda/lib/python3.11/site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<2.0.0,>=1.0.2 in ./.conda/lib/python3.11/site-packages (from langgraph) (1.0.8)\n",
      "Requirement already satisfied: aiosqlite<0.21.0,>=0.20.0 in ./.conda/lib/python3.11/site-packages (from langgraph-checkpoint-sqlite) (0.20.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.conda/lib/python3.11/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.conda/lib/python3.11/site-packages (from requests) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.conda/lib/python3.11/site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.conda/lib/python3.11/site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.conda/lib/python3.11/site-packages (from aiohttp) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.conda/lib/python3.11/site-packages (from aiohttp) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.conda/lib/python3.11/site-packages (from aiohttp) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.conda/lib/python3.11/site-packages (from aiohttp) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.conda/lib/python3.11/site-packages (from aiohttp) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.conda/lib/python3.11/site-packages (from aiohttp) (1.9.8)\n",
      "Requirement already satisfied: six>=1.9.0 in ./.conda/lib/python3.11/site-packages (from kubernetes) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in ./.conda/lib/python3.11/site-packages (from kubernetes) (2.9.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in ./.conda/lib/python3.11/site-packages (from kubernetes) (2.34.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in ./.conda/lib/python3.11/site-packages (from kubernetes) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in ./.conda/lib/python3.11/site-packages (from kubernetes) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in ./.conda/lib/python3.11/site-packages (from kubernetes) (3.2.2)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in ./.conda/lib/python3.11/site-packages (from aiosqlite<0.21.0,>=0.20.0->langgraph-checkpoint-sqlite) (4.12.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./.conda/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.conda/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./.conda/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes) (4.9)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.conda/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.38->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./.conda/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.38->langchain) (24.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.conda/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.conda/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.conda/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./.conda/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
      "Requirement already satisfied: anyio in ./.conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.4.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./.conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\n",
      "Requirement already satisfied: sniffio in ./.conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.conda/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.conda/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.38->langchain) (3.0.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in ./.conda/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes) (0.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain langgraph langgraph-checkpoint-sqlite requests termcolor aiohttp python-dotenv kubernetes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building Blocks\n",
    "\n",
    "### OpenShift Configuration\n",
    "\n",
    "Here, we set up the configuration for connecting to an **OpenShift** cluster. Environment variables are used to securely store connection details, such as the OpenShift API URL, Console URL, and access token. These details are loaded using the `dotenv` library to avoid hardcoding sensitive information in the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenShift Service connected. API is healthy.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gsampaio/redhat/ai/virt-llm-agents/.conda/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.rosa-9hg24.yena.p1.openshiftapps.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from services.openshift_service import OpenShiftService\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openshift_config = {\n",
    "    \"api_url\": os.getenv(\"OPENSHIFT_API_URL\"),\n",
    "    \"console_url\": os.getenv(\"OPENSHIFT_CONSOLE_URL\"),\n",
    "    \"token\": os.getenv(\"OPENSHIFT_TOKEN\"),\n",
    "    \"inventory_route\": os.getenv(\"OPENSHIFT_INVENTORY_ROUTE\"),\n",
    "}\n",
    "\n",
    "openshift_service = OpenShiftService(openshift_config=openshift_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Connectivity to OpenShift\n",
    "\n",
    "In this section, we test the connection to the OpenShift environment using the credentials provided in the previous configuration step. The goal is to ensure that we can successfully connect to OpenShift, retrieve resources, and interact with the cluster.\n",
    "\n",
    "We use the following steps:\n",
    "\n",
    "1. **Connect to OpenShift** using the API URL and access token stored in the environment variables.\n",
    "2. **Retrieve resources** such as pods or VMs using a custom service class (`OpenShiftService`).\n",
    "3. **Handle errors** if there's an issue connecting or retrieving data.\n",
    "4. **Disconnect** from the service once the operation is complete to free up resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gsampaio/redhat/ai/virt-llm-agents/.conda/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.rosa-9hg24.yena.p1.openshiftapps.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenShift Service connected. API is healthy.\n",
      "OpenShift Service connected. API is healthy.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gsampaio/redhat/ai/virt-llm-agents/.conda/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.rosa-9hg24.yena.p1.openshiftapps.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Union\n",
    "\n",
    "def check_openshift_connection() -> Union[bool, str]:\n",
    "    \"\"\"\n",
    "    A tool that checks the connection to the OpenShift Console.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the connection to the OpenShift Console is successful.\n",
    "        str: Error message if the connection fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create an OpenShiftService instance and attempt to establish a connection\n",
    "        client = OpenShiftService(openshift_config=openshift_config)\n",
    "\n",
    "        # Attempt to connect\n",
    "        connection_successful = (\n",
    "            openshift_service._test_connection()\n",
    "        )  # Assuming this method exists\n",
    "        \n",
    "        # Return the result\n",
    "        if connection_successful:\n",
    "            return True\n",
    "        else:\n",
    "            return \"Failed to connect to the OpenShift Console.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Connection error: {str(e)}\"\n",
    "\n",
    "check_openshift_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuring a Simple Model\n",
    "\n",
    "In this section, we configure the machine learning model that our agent will use to process tasks. The `ModelService` class manages the interaction with the model, allowing the agent to handle tasks such as managing OpenShift resources or retrieving details.\n",
    "\n",
    "### Model Configuration\n",
    "\n",
    "We initialize the `ModelService` with a specific model configuration. This step enables our agent to perform model-based tasks using the provided configuration, such as responding to queries or interacting with the OpenShift environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from services.model_service import ModelService\n",
    "\n",
    "# Initialize the service with the model configuration\n",
    "ollama_service = ModelService(model=\"llama3.1:8b-instruct-fp16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Custom Tools\n",
    "\n",
    "This section explains how we integrate custom tools into the agent’s workflow. These tools allow the agent to perform specific tasks like managing OpenShift resources. We define tools using the `@tool` decorator from `langchain` that interact with OpenShift and perform actions such as creating or migrating resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "from langchain.tools import tool\n",
    "from services.openshift_service import OpenShiftService\n",
    "\n",
    "@tool(parse_docstring=True)\n",
    "def create_migration_plan_tool(\n",
    "    vm_names: List[str],\n",
    "    name: str,\n",
    "    source: str = \"vmware\",\n",
    ") -> Union[Dict, str]:\n",
    "    \"\"\"\n",
    "    A tool to create a migration plan for moving virtual machines (VMs) using the forklift.konveyor.io API. This tool only requires VM names, and the corresponding IDs are fetched automatically.\n",
    "\n",
    "    Args:\n",
    "        vm_names: A list of VM names to migrate. This arg is mandatory.\n",
    "        name: The name of the migration plan. This arg is mandatory.\n",
    "        source: The source provider. Default is 'vmware'.\n",
    "\n",
    "    Returns:\n",
    "        dict: The created migration plan if successful.\n",
    "        str: An error message if the operation fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create an OpenShiftService instance\n",
    "        OpenShiftService(openshift_config=openshift_config)\n",
    "        print(\"\\n1/5 Connected to Openshift...\\n\")\n",
    "\n",
    "        # Automatically lookup the provider UUID based on the source provider name\n",
    "        vmware_provider_uuid = openshift_service.lookup_provider_uuid_by_name(\n",
    "            provider_name=\"vmware\", provider_type=\"vsphere\"\n",
    "        )\n",
    "        if isinstance(vmware_provider_uuid, str) and \"Error\" in vmware_provider_uuid:\n",
    "            return vmware_provider_uuid  # Return the error if we encountered one\n",
    "\n",
    "        if vmware_provider_uuid is None:\n",
    "            return f\"Provider '{source}' not found.\"\n",
    "        print(f\"\\n2/5 Now I have the provider {vmware_provider_uuid}...\\n\")\n",
    "\n",
    "        # If no VM names are provided, use a default VM\n",
    "        if vm_names is None:\n",
    "            return f\"Failed to create migration plan: No VM was provided!\"\n",
    "\n",
    "        # Fetch VM IDs for the given VM names\n",
    "        vms = []\n",
    "        for vm_name in vm_names:\n",
    "            vm_id = openshift_service.lookup_vm_id_by_name(\n",
    "                vmware_provider_uuid, vm_name\n",
    "            )\n",
    "\n",
    "            # Assuming error messages are distinct, e.g., returned as dicts or special error codes\n",
    "            if isinstance(vm_id, dict) and \"error\" in vm_id:\n",
    "                return vm_id[\"error\"]  # This handles the error case\n",
    "\n",
    "            # Check if VM was found\n",
    "            if vm_id:\n",
    "                vms.append({\"id\": vm_id, \"name\": vm_name})\n",
    "            else:\n",
    "                return f\"VM '{vm_name}' not found.\"\n",
    "\n",
    "        print(f\"\\n3/5 Now I have all the VM Names and all the VM IDs {vms}...\\n\")\n",
    "\n",
    "        network_map, n_uid, network_map_name = openshift_service.create_network_map()\n",
    "        storage_map, s_uid, storage_map_name = openshift_service.create_storage_map()\n",
    "\n",
    "        print(f\"\\n4/5 Now I have the Storage and Network maps {vms}...\\n\")\n",
    "\n",
    "        # Call the create_migration_plan method with the gathered information\n",
    "        result = openshift_service.create_migration_plan(\n",
    "            network_map_uid=n_uid,\n",
    "            network_map_name=network_map_name,\n",
    "            storage_map_uid=s_uid,\n",
    "            storage_map_name=storage_map_name,\n",
    "            name=name,\n",
    "            source=source,\n",
    "            vms=vms,\n",
    "        )\n",
    "\n",
    "        print(f\"\\n5/5 Migration plan RESPONSE - {result}...\\n\")\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Failed to create migration plan: {str(e)}\"\n",
    "\n",
    "\n",
    "@tool(parse_docstring=True)\n",
    "def start_migration_tool(\n",
    "    plan_name: str, namespace: str = \"openshift-mtv\"\n",
    ") -> Union[Dict, str]:\n",
    "    \"\"\"\n",
    "    A tool to start a migration for a given migration plan by its name.\n",
    "\n",
    "    Args:\n",
    "        plan_name: The name of the migration plan. The value should consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\\\\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*').\n",
    "        namespace: The namespace where the migration plan is located. Default is 'openshift-mtv'.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        dict: The migration start response if successful.\n",
    "        str: An error message if the operation fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create an OpenShiftService instance\n",
    "        OpenShiftService(openshift_config=openshift_config)\n",
    "        print(\"\\n1/4 Connected to Openshift...\\n\")\n",
    "\n",
    "        # Retrieve the full migration plan object by its name\n",
    "        migration_plan = openshift_service.get_migration_plan_by_name(\n",
    "            plan_name=plan_name, namespace=namespace\n",
    "        )\n",
    "\n",
    "        if isinstance(migration_plan, str) and \"Error\" in migration_plan:\n",
    "            return migration_plan  # Return the error if we encountered one\n",
    "\n",
    "        if migration_plan is None:\n",
    "            return f\"Migration plan '{plan_name}' not found.\"\n",
    "\n",
    "        # Retrieve the UID of the migration plan\n",
    "        plan_uid = migration_plan[\"metadata\"][\"uid\"]\n",
    "        print(f\"\\n2/4 Retrieved migration plan UID: {plan_uid}...\\n\")\n",
    "\n",
    "        # Check the status conditions to verify if the plan is ready\n",
    "        ready_status = False\n",
    "        conditions = migration_plan.get(\"status\", {}).get(\"conditions\", [])\n",
    "        for condition in conditions:\n",
    "            if condition.get(\"type\") == \"Ready\" and condition.get(\"status\") == \"True\":\n",
    "                ready_status = True\n",
    "                break\n",
    "\n",
    "        if not ready_status:\n",
    "            return f\"Migration plan '{plan_name}' is not ready.\"\n",
    "\n",
    "        print(f\"\\n3/4 Migration plan is ready. Starting migration...\\n\")\n",
    "\n",
    "        # Start the migration using the retrieved plan UID\n",
    "        result = openshift_service.start_migration(\n",
    "            plan_name=plan_name, plan_uid=plan_uid, namespace=namespace\n",
    "        )\n",
    "\n",
    "        print(f\"\\n4/4 Migration started: {result}...\\n\")\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Failed to start migration: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"name\": \"create_migration_plan_tool\",\n",
      "        \"description\": \"A tool to create a migration plan for moving virtual machines (VMs) using the forklift.konveyor.io API. This tool only requires VM names, and the corresponding IDs are fetched automatically.\",\n",
      "        \"parameters\": {\n",
      "            \"vm_names\": {\n",
      "                \"param_type\": \"str\",\n",
      "                \"description\": \"A list of VM names to migrate. This arg is mandatory.\",\n",
      "                \"required\": true\n",
      "            },\n",
      "            \"name\": {\n",
      "                \"param_type\": \"str\",\n",
      "                \"description\": \"The name of the migration plan. This arg is mandatory.\",\n",
      "                \"required\": true\n",
      "            },\n",
      "            \"source\": {\n",
      "                \"param_type\": \"str\",\n",
      "                \"description\": \"The source provider. Default is 'vmware'.\",\n",
      "                \"required\": false\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"start_migration_tool\",\n",
      "        \"description\": \"A tool to start a migration for a given migration plan by its name.\",\n",
      "        \"parameters\": {\n",
      "            \"plan_name\": {\n",
      "                \"param_type\": \"str\",\n",
      "                \"description\": \"The name of the migration plan. The value should consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\\\\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*').\",\n",
      "                \"required\": true\n",
      "            },\n",
      "            \"namespace\": {\n",
      "                \"param_type\": \"str\",\n",
      "                \"description\": \"The namespace where the migration plan is located. Default is 'openshift-mtv'.\",\n",
      "                \"required\": false\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from utils.general.tools import (\n",
    "    get_tools_name,\n",
    "    get_tools_description_json,\n",
    ")\n",
    "\n",
    "tools = [create_migration_plan_tool, start_migration_tool]\n",
    "\n",
    "tools_name = get_tools_name(tools)\n",
    "tools_description_json = get_tools_description_json(tools)\n",
    "\n",
    "tools_description = json.dumps(tools_description_json, indent=4)\n",
    "\n",
    "print(tools_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Workflow Graph Setup\n",
    "\n",
    "### Node: `react_node_function`\n",
    "\n",
    "This function handles the execution of tasks by the ReAct agent. It takes the current state of the agent and processes the user request using the available tools (such as listing resources or retrieving details). The response from the ReAct agent is returned as the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from state.agent_graph import AgentGraphState\n",
    "from agent.react_agent import ReactAgent\n",
    "\n",
    "def react_node_function(state: AgentGraphState):\n",
    "    react_agent = ReactAgent(\n",
    "        state=state,\n",
    "        role=\"REACT_AGENT\",\n",
    "        tools=tools,\n",
    "        ollama_service=ollama_service,\n",
    "    )\n",
    "\n",
    "    return react_agent.react(user_request=state[\"input\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State Graph\n",
    "\n",
    "In this step, we define a `StateGraph` using the `AgentGraphState`. The graph determines the flow of tasks through various agent nodes, using an AI-driven ReAct agent to process tasks based on the inputs it receives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "\n",
    "def create_graph() -> StateGraph:\n",
    "    \"\"\"\n",
    "    Create the state graph by defining nodes and edges.\n",
    "\n",
    "    Returns:\n",
    "    - StateGraph: The compiled state graph ready for execution.\n",
    "    \"\"\"\n",
    "    graph = StateGraph(AgentGraphState)\n",
    "\n",
    "    # Add nodes\n",
    "    graph.add_node(\"react_agent\", react_node_function)\n",
    "\n",
    "    # Define the flow of the graph\n",
    "    graph.add_edge(START, \"react_agent\")\n",
    "    graph.add_edge(\"react_agent\", END)\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Sqlite Persistence for Graph State\n",
    "\n",
    "In this step, we set up persistence for the agent's state using SQLite. This allows us to store the state in an SQLite database, ensuring that the workflow’s context is preserved even after multiple interactions. The `SqliteSaver` class handles the saving and retrieval of this state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "def from_conn_stringx(\n",
    "    cls,\n",
    "    conn_string: str,\n",
    ") -> \"SqliteSaver\":\n",
    "    return SqliteSaver(conn=sqlite3.connect(conn_string, check_same_thread=False))\n",
    "\n",
    "\n",
    "SqliteSaver.from_conn_stringx = classmethod(from_conn_stringx)\n",
    "\n",
    "memory = SqliteSaver.from_conn_stringx(\":memory:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Executing the Workflow\n",
    "\n",
    "Here, we execute the workflow by compiling the state graph and defining the inputs for the agent. The agent processes user requests (such as listing resources) and streams the events as it progresses through the workflow. This allows us to see the state of the agent at each step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 1: Create a Migration Plan for a VM\n",
    "\n",
    "In this query, we instruct the AI agent to perform a single task: **create a migration plan** for a virtual machine (VM) named `database`. The agent is explicitly told to focus only on creating the migration plan and not to retrieve any additional details about the VM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph and workflow created.\n",
      "\u001b[32m<|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "You should execute only one task. THIS IS A SINGLE TASK: Use the create_migration_plan_tool to create a migration plan for the vm named 'database'! REMEMBER: DON'T DO ANY ADDITIONAL STEP! DO NOT START OR EXECUTE THE MIGRATION YET! <|eot_id|>\u001b[0m\n",
      "\u001b[36m<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\n",
      "    \"thought\": \"To create a migration plan, I need to use the create_migration_plan_tool with the correct input.\",\n",
      "    \"action\": \"create_migration_plan_tool\",\n",
      "    \"action_input\": {\n",
      "        \"vm_names\": [\n",
      "            \"database\"\n",
      "        ],\n",
      "        \"name\": \"migration-plan-database\",\n",
      "        \"source\": \"vmware\"\n",
      "    }\n",
      "}<|eot_id|>\u001b[0m\n",
      "\u001b[35m<|python_tag|>create_migration_plan_tool.call({'vm_names': ['database'], 'name': 'migration-plan-database', 'source': 'vmware'})\n",
      "<|eom_id|>\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gsampaio/redhat/ai/virt-llm-agents/.conda/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.rosa-9hg24.yena.p1.openshiftapps.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenShift Service connected. API is healthy.\n",
      "\n",
      "1/5 Connected to Openshift...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gsampaio/redhat/ai/virt-llm-agents/.conda/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'forklift-inventory-openshift-mtv.apps.rosa-9hg24.yena.p1.openshiftapps.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2/5 Now I have the provider a1699c04-47c7-4864-852e-f3877bc889e9...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gsampaio/redhat/ai/virt-llm-agents/.conda/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'forklift-inventory-openshift-mtv.apps.rosa-9hg24.yena.p1.openshiftapps.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3/5 Now I have all the VM Names and all the VM IDs [{'id': 'vm-88352', 'name': 'database'}]...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gsampaio/redhat/ai/virt-llm-agents/.conda/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.rosa-9hg24.yena.p1.openshiftapps.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/gsampaio/redhat/ai/virt-llm-agents/.conda/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.rosa-9hg24.yena.p1.openshiftapps.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4/5 Now I have the Storage and Network maps [{'id': 'vm-88352', 'name': 'database'}]...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gsampaio/redhat/ai/virt-llm-agents/.conda/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'forklift-inventory-openshift-mtv.apps.rosa-9hg24.yena.p1.openshiftapps.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/gsampaio/redhat/ai/virt-llm-agents/.conda/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'forklift-inventory-openshift-mtv.apps.rosa-9hg24.yena.p1.openshiftapps.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/gsampaio/redhat/ai/virt-llm-agents/.conda/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.rosa-9hg24.yena.p1.openshiftapps.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5/5 Migration plan RESPONSE - {'apiVersion': 'forklift.konveyor.io/v1beta1', 'kind': 'Plan', 'metadata': {'annotations': {'populatorLabels': 'True'}, 'creationTimestamp': '2024-09-06T14:44:34Z', 'generation': 1, 'managedFields': [{'apiVersion': 'forklift.konveyor.io/v1beta1', 'fieldsType': 'FieldsV1', 'fieldsV1': {'f:spec': {'.': {}, 'f:map': {'.': {}, 'f:network': {}, 'f:storage': {}}, 'f:provider': {'.': {}, 'f:destination': {}, 'f:source': {}}, 'f:targetNamespace': {}, 'f:vms': {}}}, 'manager': 'OpenAPI-Generator', 'operation': 'Update', 'time': '2024-09-06T14:44:34Z'}], 'name': 'migration-plan-database', 'namespace': 'openshift-mtv', 'resourceVersion': '2008751', 'uid': '37a38c7f-a87e-4e88-83c0-0a6780dd8093'}, 'spec': {'map': {'network': {'apiVersion': 'forklift.konveyor.io/v1beta1', 'kind': 'NetworkMap', 'name': 'vmware-k4bhm', 'namespace': 'openshift-mtv', 'uid': '0e5f7d08-6cd8-4369-85fd-a2b9309f115a'}, 'storage': {'apiVersion': 'forklift.konveyor.io/v1beta1', 'kind': 'StorageMap', 'name': 'vmware-bzqpl', 'namespace': 'openshift-mtv', 'uid': '55ee34c5-2960-492a-ab6b-0bd441407d39'}}, 'provider': {'destination': {'apiVersion': 'forklift.konveyor.io/v1beta1', 'kind': 'Provider', 'name': 'host', 'namespace': 'openshift-mtv', 'uid': 'c07f4f30-c9a4-4c04-894e-5414820311b8'}, 'source': {'apiVersion': 'forklift.konveyor.io/v1beta1', 'kind': 'Provider', 'name': 'vmware', 'namespace': 'openshift-mtv', 'uid': 'a1699c04-47c7-4864-852e-f3877bc889e9'}}, 'targetNamespace': 'openshift-mtv', 'vms': [{'id': 'vm-88352', 'name': 'database'}]}}...\n",
      "\n",
      "\u001b[35m<|start_header_id|>ipython<|end_header_id|>\n",
      "\n",
      "{'apiVersion': 'forklift.konveyor.io/v1beta1', 'kind': 'Plan', 'metadata': {'annotations': {'populatorLabels': 'True'}, 'creationTimestamp': '2024-09-06T14:44:34Z', 'generation': 1, 'managedFields': [{'apiVersion': 'forklift.konveyor.io/v1beta1', 'fieldsType': 'FieldsV1', 'fieldsV1': {'f:spec': {'.': {}, 'f:map': {'.': {}, 'f:network': {}, 'f:storage': {}}, 'f:provider': {'.': {}, 'f:destination': {}, 'f:source': {}}, 'f:targetNamespace': {}, 'f:vms': {}}}, 'manager': 'OpenAPI-Generator', 'operation': 'Update', 'time': '2024-09-06T14:44:34Z'}], 'name': 'migration-plan-database', 'namespace': 'openshift-mtv', 'resourceVersion': '2008751', 'uid': '37a38c7f-a87e-4e88-83c0-0a6780dd8093'}, 'spec': {'map': {'network': {'apiVersion': 'forklift.konveyor.io/v1beta1', 'kind': 'NetworkMap', 'name': 'vmware-k4bhm', 'namespace': 'openshift-mtv', 'uid': '0e5f7d08-6cd8-4369-85fd-a2b9309f115a'}, 'storage': {'apiVersion': 'forklift.konveyor.io/v1beta1', 'kind': 'StorageMap', 'name': 'vmware-bzqpl', 'namespace': 'openshift-mtv', 'uid': '55ee34c5-2960-492a-ab6b-0bd441407d39'}}, 'provider': {'destination': {'apiVersion': 'forklift.konveyor.io/v1beta1', 'kind': 'Provider', 'name': 'host', 'namespace': 'openshift-mtv', 'uid': 'c07f4f30-c9a4-4c04-894e-5414820311b8'}, 'source': {'apiVersion': 'forklift.konveyor.io/v1beta1', 'kind': 'Provider', 'name': 'vmware', 'namespace': 'openshift-mtv', 'uid': 'a1699c04-47c7-4864-852e-f3877bc889e9'}}, 'targetNamespace': 'openshift-mtv', 'vms': [{'id': 'vm-88352', 'name': 'database'}]}}<|eot_id|>\u001b[0m\n",
      "\u001b[33m<|start_header_id|>ipython<|end_header_id|>\n",
      "\n",
      "{\n",
      "    \"observation\": {\n",
      "        \"apiVersion\": \"forklift.konveyor.io/v1beta1\",\n",
      "        \"kind\": \"Plan\",\n",
      "        \"metadata\": {\n",
      "            \"annotations\": {\n",
      "                \"populatorLabels\": \"True\"\n",
      "            },\n",
      "            \"creationTimestamp\": \"2024-09-06T14:44:34Z\",\n",
      "            \"generation\": 1,\n",
      "            \"managedFields\": [\n",
      "                {\n",
      "                    \"apiVersion\": \"forklift.konveyor.io/v1beta1\",\n",
      "                    \"fieldsType\": \"FieldsV1\",\n",
      "                    \"fieldsV1\": {\n",
      "                        \"f:spec\": {\n",
      "                            \".\": {},\n",
      "                            \"f:map\": {\n",
      "                                \".\": {},\n",
      "                                \"f:network\": {},\n",
      "                                \"f:storage\": {}\n",
      "                            },\n",
      "                            \"f:provider\": {\n",
      "                                \".\": {},\n",
      "                                \"f:destination\": {},\n",
      "                                \"f:source\": {}\n",
      "                            },\n",
      "                            \"f:targetNamespace\": {},\n",
      "                            \"f:vms\": {}\n",
      "                        }\n",
      "                    },\n",
      "                    \"manager\": \"OpenAPI-Generator\",\n",
      "                    \"operation\": \"Update\",\n",
      "                    \"time\": \"2024-09-06T14:44:34Z\"\n",
      "                }\n",
      "            ],\n",
      "            \"name\": \"migration-plan-database\",\n",
      "            \"namespace\": \"openshift-mtv\",\n",
      "            \"resourceVersion\": \"2008751\",\n",
      "            \"uid\": \"37a38c7f-a87e-4e88-83c0-0a6780dd8093\"\n",
      "        },\n",
      "        \"spec\": {\n",
      "            \"map\": {\n",
      "                \"network\": {\n",
      "                    \"apiVersion\": \"forklift.konveyor.io/v1beta1\",\n",
      "                    \"kind\": \"NetworkMap\",\n",
      "                    \"name\": \"vmware-k4bhm\",\n",
      "                    \"namespace\": \"openshift-mtv\",\n",
      "                    \"uid\": \"0e5f7d08-6cd8-4369-85fd-a2b9309f115a\"\n",
      "                },\n",
      "                \"storage\": {\n",
      "                    \"apiVersion\": \"forklift.konveyor.io/v1beta1\",\n",
      "                    \"kind\": \"StorageMap\",\n",
      "                    \"name\": \"vmware-bzqpl\",\n",
      "                    \"namespace\": \"openshift-mtv\",\n",
      "                    \"uid\": \"55ee34c5-2960-492a-ab6b-0bd441407d39\"\n",
      "                }\n",
      "            },\n",
      "            \"provider\": {\n",
      "                \"destination\": {\n",
      "                    \"apiVersion\": \"forklift.konveyor.io/v1beta1\",\n",
      "                    \"kind\": \"Provider\",\n",
      "                    \"name\": \"host\",\n",
      "                    \"namespace\": \"openshift-mtv\",\n",
      "                    \"uid\": \"c07f4f30-c9a4-4c04-894e-5414820311b8\"\n",
      "                },\n",
      "                \"source\": {\n",
      "                    \"apiVersion\": \"forklift.konveyor.io/v1beta1\",\n",
      "                    \"kind\": \"Provider\",\n",
      "                    \"name\": \"vmware\",\n",
      "                    \"namespace\": \"openshift-mtv\",\n",
      "                    \"uid\": \"a1699c04-47c7-4864-852e-f3877bc889e9\"\n",
      "                }\n",
      "            },\n",
      "            \"targetNamespace\": \"openshift-mtv\",\n",
      "            \"vms\": [\n",
      "                {\n",
      "                    \"id\": \"vm-88352\",\n",
      "                    \"name\": \"database\"\n",
      "                }\n",
      "            ]\n",
      "        }\n",
      "    }\n",
      "}<|eot_id|>\u001b[0m\n",
      "\u001b[36m<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\n",
      "    \"answer\": \"I have the answer: {\\\"apiVersion\\\": \\\"forklift.konveyor.io/v1beta1\\\", \\\"kind\\\": \\\"Plan\\\", ...}\"\n",
      "}<|eot_id|>\u001b[0m\n",
      "\n",
      "Event: {'react_agent': {'response': AIMessage(content='I have the answer: {\"apiVersion\": \"forklift.konveyor.io/v1beta1\", \"kind\": \"Plan\", ...}'), 'tool_response': SystemMessage(content=\"{'apiVersion': 'forklift.konveyor.io/v1beta1', 'kind': 'Plan', 'metadata': {'annotations': {'populatorLabels': 'True'}, 'creationTimestamp': '2024-09-06T14:44:34Z', 'generation': 1, 'managedFields': [{'apiVersion': 'forklift.konveyor.io/v1beta1', 'fieldsType': 'FieldsV1', 'fieldsV1': {'f:spec': {'.': {}, 'f:map': {'.': {}, 'f:network': {}, 'f:storage': {}}, 'f:provider': {'.': {}, 'f:destination': {}, 'f:source': {}}, 'f:targetNamespace': {}, 'f:vms': {}}}, 'manager': 'OpenAPI-Generator', 'operation': 'Update', 'time': '2024-09-06T14:44:34Z'}], 'name': 'migration-plan-database', 'namespace': 'openshift-mtv', 'resourceVersion': '2008751', 'uid': '37a38c7f-a87e-4e88-83c0-0a6780dd8093'}, 'spec': {'map': {'network': {'apiVersion': 'forklift.konveyor.io/v1beta1', 'kind': 'NetworkMap', 'name': 'vmware-k4bhm', 'namespace': 'openshift-mtv', 'uid': '0e5f7d08-6cd8-4369-85fd-a2b9309f115a'}, 'storage': {'apiVersion': 'forklift.konveyor.io/v1beta1', 'kind': 'StorageMap', 'name': 'vmware-bzqpl', 'namespace': 'openshift-mtv', 'uid': '55ee34c5-2960-492a-ab6b-0bd441407d39'}}, 'provider': {'destination': {'apiVersion': 'forklift.konveyor.io/v1beta1', 'kind': 'Provider', 'name': 'host', 'namespace': 'openshift-mtv', 'uid': 'c07f4f30-c9a4-4c04-894e-5414820311b8'}, 'source': {'apiVersion': 'forklift.konveyor.io/v1beta1', 'kind': 'Provider', 'name': 'vmware', 'namespace': 'openshift-mtv', 'uid': 'a1699c04-47c7-4864-852e-f3877bc889e9'}}, 'targetNamespace': 'openshift-mtv', 'vms': [{'id': 'vm-88352', 'name': 'database'}]}}\")}}\n"
     ]
    }
   ],
   "source": [
    "# Create the graph and compile the workflow\n",
    "graph = create_graph()\n",
    "workflow = graph.compile(checkpointer=memory)\n",
    "print(\"Graph and workflow created.\")\n",
    "\n",
    "# Define workflow parameters\n",
    "iterations = 10\n",
    "verbose = True\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "vm_name = \"database\"\n",
    "query = f\"You should execute only one task. THIS IS A SINGLE TASK: Use the create_migration_plan_tool to create a migration plan for the vm named '{vm_name}'! REMEMBER: DON'T DO ANY ADDITIONAL STEP! DO NOT START OR EXECUTE THE MIGRATION YET! \"\n",
    "dict_inputs = {\"input\": query}\n",
    "limit = {\"recursion_limit\": iterations}\n",
    "\n",
    "# Execute the workflow and print state changes\n",
    "for event in workflow.stream(dict_inputs, config):\n",
    "    if verbose:\n",
    "            print(\"\\nEvent:\", event)\n",
    "    else:\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Agent's Output\n",
    "\n",
    "After the agent completes its task (e.g., listing VMs), we save the output to a JSON file for future reference or analysis. We use the `save_json_to_file` function to handle this, ensuring that the output is saved in a well-formatted, pretty-printed JSON file.\n",
    "\n",
    "**Function**: `remove_prefix`\n",
    "This helper function extracts a removes the `I have the answer: ` prefix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"apiVersion\": \"forklift.konveyor.io/v1beta1\",\n",
      "    \"kind\": \"Plan\",\n",
      "    \"metadata\": {\n",
      "        \"annotations\": {\n",
      "            \"populatorLabels\": \"True\"\n",
      "        },\n",
      "        \"creationTimestamp\": \"2024-09-06T14:44:34Z\",\n",
      "        \"generation\": 1,\n",
      "        \"managedFields\": [\n",
      "            {\n",
      "                \"apiVersion\": \"forklift.konveyor.io/v1beta1\",\n",
      "                \"fieldsType\": \"FieldsV1\",\n",
      "                \"fieldsV1\": {\n",
      "                    \"f:spec\": {\n",
      "                        \".\": {},\n",
      "                        \"f:map\": {\n",
      "                            \".\": {},\n",
      "                            \"f:network\": {},\n",
      "                            \"f:storage\": {}\n",
      "                        },\n",
      "                        \"f:provider\": {\n",
      "                            \".\": {},\n",
      "                            \"f:destination\": {},\n",
      "                            \"f:source\": {}\n",
      "                        },\n",
      "                        \"f:targetNamespace\": {},\n",
      "                        \"f:vms\": {}\n",
      "                    }\n",
      "                },\n",
      "                \"manager\": \"OpenAPI-Generator\",\n",
      "                \"operation\": \"Update\",\n",
      "                \"time\": \"2024-09-06T14:44:34Z\"\n",
      "            }\n",
      "        ],\n",
      "        \"name\": \"migration-plan-database\",\n",
      "        \"namespace\": \"openshift-mtv\",\n",
      "        \"resourceVersion\": \"2008751\",\n",
      "        \"uid\": \"37a38c7f-a87e-4e88-83c0-0a6780dd8093\"\n",
      "    },\n",
      "    \"spec\": {\n",
      "        \"map\": {\n",
      "            \"network\": {\n",
      "                \"apiVersion\": \"forklift.konveyor.io/v1beta1\",\n",
      "                \"kind\": \"NetworkMap\",\n",
      "                \"name\": \"vmware-k4bhm\",\n",
      "                \"namespace\": \"openshift-mtv\",\n",
      "                \"uid\": \"0e5f7d08-6cd8-4369-85fd-a2b9309f115a\"\n",
      "            },\n",
      "            \"storage\": {\n",
      "                \"apiVersion\": \"forklift.konveyor.io/v1beta1\",\n",
      "                \"kind\": \"StorageMap\",\n",
      "                \"name\": \"vmware-bzqpl\",\n",
      "                \"namespace\": \"openshift-mtv\",\n",
      "                \"uid\": \"55ee34c5-2960-492a-ab6b-0bd441407d39\"\n",
      "            }\n",
      "        },\n",
      "        \"provider\": {\n",
      "            \"destination\": {\n",
      "                \"apiVersion\": \"forklift.konveyor.io/v1beta1\",\n",
      "                \"kind\": \"Provider\",\n",
      "                \"name\": \"host\",\n",
      "                \"namespace\": \"openshift-mtv\",\n",
      "                \"uid\": \"c07f4f30-c9a4-4c04-894e-5414820311b8\"\n",
      "            },\n",
      "            \"source\": {\n",
      "                \"apiVersion\": \"forklift.konveyor.io/v1beta1\",\n",
      "                \"kind\": \"Provider\",\n",
      "                \"name\": \"vmware\",\n",
      "                \"namespace\": \"openshift-mtv\",\n",
      "                \"uid\": \"a1699c04-47c7-4864-852e-f3877bc889e9\"\n",
      "            }\n",
      "        },\n",
      "        \"targetNamespace\": \"openshift-mtv\",\n",
      "        \"vms\": [\n",
      "            {\n",
      "                \"id\": \"vm-88352\",\n",
      "                \"name\": \"database\"\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "}\n",
      "JSON saved successfully to data/migration_plan_output.json\n"
     ]
    }
   ],
   "source": [
    "from utils.general.helpers import save_json_to_file, remove_prefix\n",
    "\n",
    "# Assuming workflow.get_state() returns some structured data\n",
    "state_snapshot = workflow.get_state(config)\n",
    "\n",
    "# Check if there's any response\n",
    "if state_snapshot.values[\"tool_response\"]:\n",
    "\n",
    "    # Extract the list of VMs\n",
    "    extracted_json_string = remove_prefix(state_snapshot.values[\"tool_response\"][-1].content)\n",
    "    cleaned_content = extracted_json_string.strip().rstrip(\n",
    "        \".\"\n",
    "    )  # Removing trailing period\n",
    "\n",
    "    cleaned_content = cleaned_content.replace(\"'\", '\"')\n",
    "    extracted_json = json.loads(cleaned_content)\n",
    "\n",
    "    print(json.dumps(extracted_json, indent=4))\n",
    "\n",
    "    save_json_to_file(extracted_json, \"data/migration_plan_output.json\")\n",
    "else:\n",
    "    print(\"There's no migration plan to save!\")\n",
    "\n",
    "migration_plan_name = extracted_json[\"metadata\"][\"name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Start the Migration Plan\n",
    "\n",
    "### Query 2: Start the Migration Plan\n",
    "\n",
    "Here, we provide a query asking the agent to start a migration plan for specific OpenShift resources. The agent processes the request, and the migration is triggered within the OpenShift environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m<|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "You should execute only one task. THIS IS A SINGLE TASK: Use the start_migration_plan_tool to start the migration-plan-database! REMEMBER: DON'T DO ANY ADDITIONAL STEP! DO NOT CREATE THE MIGRATION! <|eot_id|>\u001b[0m\n",
      "\u001b[36m<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\n",
      "    \"thought\": \"To start the migration plan 'migration-plan-database', I need to use the start_migration_tool.\",\n",
      "    \"action\": \"start_migration_plan_tool\",\n",
      "    \"action_input\": {\n",
      "        \"plan_name\": \"migration-plan-database\"\n",
      "    }\n",
      "}<|eot_id|>\u001b[0m\n",
      "\u001b[35m<|python_tag|>start_migration_plan_tool.call({'plan_name': 'migration-plan-database'})\n",
      "<|eom_id|>\u001b[0m\n",
      "too many values to unpack (expected 2)\n",
      "\u001b[36m<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\n",
      "    \"thought\": \"To start the migration plan 'migration-plan-database', I need to use the start_migration_tool.\",\n",
      "    \"action\": \"start_migration_tool\",\n",
      "    \"action_input\": {\n",
      "        \"plan_name\": \"migration-plan-database\"\n",
      "    }\n",
      "}<|eot_id|>\u001b[0m\n",
      "\u001b[35m<|python_tag|>start_migration_tool.call({'plan_name': 'migration-plan-database'})\n",
      "<|eom_id|>\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gsampaio/redhat/ai/virt-llm-agents/.conda/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.rosa-9hg24.yena.p1.openshiftapps.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenShift Service connected. API is healthy.\n",
      "\n",
      "1/4 Connected to Openshift...\n",
      "\n",
      "\n",
      "2/4 Retrieved migration plan UID: 37a38c7f-a87e-4e88-83c0-0a6780dd8093...\n",
      "\n",
      "\n",
      "3/4 Migration plan is ready. Starting migration...\n",
      "\n",
      "\n",
      "4/4 Migration started: {'apiVersion': 'forklift.konveyor.io/v1beta1', 'kind': 'Migration', 'metadata': {'creationTimestamp': '2024-09-06T14:44:50Z', 'generateName': 'migration-plan-database-', 'generation': 1, 'managedFields': [{'apiVersion': 'forklift.konveyor.io/v1beta1', 'fieldsType': 'FieldsV1', 'fieldsV1': {'f:metadata': {'f:generateName': {}, 'f:ownerReferences': {'.': {}, 'k:{\"uid\":\"37a38c7f-a87e-4e88-83c0-0a6780dd8093\"}': {}}}, 'f:spec': {'.': {}, 'f:plan': {}}}, 'manager': 'python-requests', 'operation': 'Update', 'time': '2024-09-06T14:44:50Z'}], 'name': 'migration-plan-database-h2tcz', 'namespace': 'openshift-mtv', 'ownerReferences': [{'apiVersion': 'forklift.konveyor.io/v1beta1', 'kind': 'Plan', 'name': 'migration-plan-database', 'uid': '37a38c7f-a87e-4e88-83c0-0a6780dd8093'}], 'resourceVersion': '2009301', 'uid': '19efc924-a06b-4398-9059-5560254f720e'}, 'spec': {'plan': {'name': 'migration-plan-database', 'namespace': 'openshift-mtv', 'uid': '37a38c7f-a87e-4e88-83c0-0a6780dd8093'}}}...\n",
      "\n",
      "\u001b[35m<|start_header_id|>ipython<|end_header_id|>\n",
      "\n",
      "{'apiVersion': 'forklift.konveyor.io/v1beta1', 'kind': 'Migration', 'metadata': {'creationTimestamp': '2024-09-06T14:44:50Z', 'generateName': 'migration-plan-database-', 'generation': 1, 'managedFields': [{'apiVersion': 'forklift.konveyor.io/v1beta1', 'fieldsType': 'FieldsV1', 'fieldsV1': {'f:metadata': {'f:generateName': {}, 'f:ownerReferences': {'.': {}, 'k:{\"uid\":\"37a38c7f-a87e-4e88-83c0-0a6780dd8093\"}': {}}}, 'f:spec': {'.': {}, 'f:plan': {}}}, 'manager': 'python-requests', 'operation': 'Update', 'time': '2024-09-06T14:44:50Z'}], 'name': 'migration-plan-database-h2tcz', 'namespace': 'openshift-mtv', 'ownerReferences': [{'apiVersion': 'forklift.konveyor.io/v1beta1', 'kind': 'Plan', 'name': 'migration-plan-database', 'uid': '37a38c7f-a87e-4e88-83c0-0a6780dd8093'}], 'resourceVersion': '2009301', 'uid': '19efc924-a06b-4398-9059-5560254f720e'}, 'spec': {'plan': {'name': 'migration-plan-database', 'namespace': 'openshift-mtv', 'uid': '37a38c7f-a87e-4e88-83c0-0a6780dd8093'}}}<|eot_id|>\u001b[0m\n",
      "\u001b[33m<|start_header_id|>ipython<|end_header_id|>\n",
      "\n",
      "{\n",
      "    \"observation\": {\n",
      "        \"apiVersion\": \"forklift.konveyor.io/v1beta1\",\n",
      "        \"kind\": \"Migration\",\n",
      "        \"metadata\": {\n",
      "            \"creationTimestamp\": \"2024-09-06T14:44:50Z\",\n",
      "            \"generateName\": \"migration-plan-database-\",\n",
      "            \"generation\": 1,\n",
      "            \"managedFields\": [\n",
      "                {\n",
      "                    \"apiVersion\": \"forklift.konveyor.io/v1beta1\",\n",
      "                    \"fieldsType\": \"FieldsV1\",\n",
      "                    \"fieldsV1\": {\n",
      "                        \"f:metadata\": {\n",
      "                            \"f:generateName\": {},\n",
      "                            \"f:ownerReferences\": {\n",
      "                                \".\": {},\n",
      "                                \"k:{\\\"uid\\\":\\\"37a38c7f-a87e-4e88-83c0-0a6780dd8093\\\"}\": {}\n",
      "                            }\n",
      "                        },\n",
      "                        \"f:spec\": {\n",
      "                            \".\": {},\n",
      "                            \"f:plan\": {}\n",
      "                        }\n",
      "                    },\n",
      "                    \"manager\": \"python-requests\",\n",
      "                    \"operation\": \"Update\",\n",
      "                    \"time\": \"2024-09-06T14:44:50Z\"\n",
      "                }\n",
      "            ],\n",
      "            \"name\": \"migration-plan-database-h2tcz\",\n",
      "            \"namespace\": \"openshift-mtv\",\n",
      "            \"ownerReferences\": [\n",
      "                {\n",
      "                    \"apiVersion\": \"forklift.konveyor.io/v1beta1\",\n",
      "                    \"kind\": \"Plan\",\n",
      "                    \"name\": \"migration-plan-database\",\n",
      "                    \"uid\": \"37a38c7f-a87e-4e88-83c0-0a6780dd8093\"\n",
      "                }\n",
      "            ],\n",
      "            \"resourceVersion\": \"2009301\",\n",
      "            \"uid\": \"19efc924-a06b-4398-9059-5560254f720e\"\n",
      "        },\n",
      "        \"spec\": {\n",
      "            \"plan\": {\n",
      "                \"name\": \"migration-plan-database\",\n",
      "                \"namespace\": \"openshift-mtv\",\n",
      "                \"uid\": \"37a38c7f-a87e-4e88-83c0-0a6780dd8093\"\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}<|eot_id|>\u001b[0m\n",
      "\u001b[36m<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\n",
      "    \"answer\": \"I have the answer: The migration plan 'migration-plan-database' has been started in namespace 'openshift-mtv'.\"\n",
      "}<|eot_id|>\u001b[0m\n",
      "\n",
      "Event: {'react_agent': {'response': AIMessage(content=\"I have the answer: The migration plan 'migration-plan-database' has been started in namespace 'openshift-mtv'.\"), 'tool_response': SystemMessage(content='{\\'apiVersion\\': \\'forklift.konveyor.io/v1beta1\\', \\'kind\\': \\'Migration\\', \\'metadata\\': {\\'creationTimestamp\\': \\'2024-09-06T14:44:50Z\\', \\'generateName\\': \\'migration-plan-database-\\', \\'generation\\': 1, \\'managedFields\\': [{\\'apiVersion\\': \\'forklift.konveyor.io/v1beta1\\', \\'fieldsType\\': \\'FieldsV1\\', \\'fieldsV1\\': {\\'f:metadata\\': {\\'f:generateName\\': {}, \\'f:ownerReferences\\': {\\'.\\': {}, \\'k:{\"uid\":\"37a38c7f-a87e-4e88-83c0-0a6780dd8093\"}\\': {}}}, \\'f:spec\\': {\\'.\\': {}, \\'f:plan\\': {}}}, \\'manager\\': \\'python-requests\\', \\'operation\\': \\'Update\\', \\'time\\': \\'2024-09-06T14:44:50Z\\'}], \\'name\\': \\'migration-plan-database-h2tcz\\', \\'namespace\\': \\'openshift-mtv\\', \\'ownerReferences\\': [{\\'apiVersion\\': \\'forklift.konveyor.io/v1beta1\\', \\'kind\\': \\'Plan\\', \\'name\\': \\'migration-plan-database\\', \\'uid\\': \\'37a38c7f-a87e-4e88-83c0-0a6780dd8093\\'}], \\'resourceVersion\\': \\'2009301\\', \\'uid\\': \\'19efc924-a06b-4398-9059-5560254f720e\\'}, \\'spec\\': {\\'plan\\': {\\'name\\': \\'migration-plan-database\\', \\'namespace\\': \\'openshift-mtv\\', \\'uid\\': \\'37a38c7f-a87e-4e88-83c0-0a6780dd8093\\'}}}')}}\n"
     ]
    }
   ],
   "source": [
    "query = f\"You should execute only one task. THIS IS A SINGLE TASK: Use the start_migration_plan_tool to start the {migration_plan_name}! REMEMBER: DON'T DO ANY ADDITIONAL STEP! DO NOT CREATE THE MIGRATION! \"\n",
    "dict_inputs = {\"input\": query}\n",
    "limit = {\"recursion_limit\": iterations}\n",
    "\n",
    "# Execute the workflow and print state changes\n",
    "for event in workflow.stream(dict_inputs, config):\n",
    "    if verbose:\n",
    "        print(\"\\nEvent:\", event)\n",
    "    else:\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates how to build an AI-powered agent that interacts with an OpenShift environment, retrieves resource information, and processes tasks using a machine learning model. The agent can perform custom tasks based on defined tools and persist its state using SQLite, making it adaptable for complex workflows in real-world environments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
