{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Building a Multi-Agent Workflow with StateGraph\n",
    "\n",
    "In this notebook, we will explore how to build a multi-agent workflow using **LangGraph's StateGraph**. A **StateGraph** allows agents to communicate through a shared state, enabling them to collaborate on complex tasks. Each node in the graph performs an action, reads from the shared state, and writes results back to it, forming a seamless workflow between agents.\n",
    "\n",
    "By the end of this notebook, you'll understand how to:\n",
    "\n",
    "- Define a shared state schema for agent communication.\n",
    "- Build and compile a `StateGraph` where nodes represent agents or actions.\n",
    "- Use multi-agent workflows to solve more complex tasks by aggregating results across different agents.\n",
    "\n",
    "## Introduction to StateGraph\n",
    "\n",
    "A `StateGraph` is a graph structure where each node represents an action or a task that modifies a shared state. The state is passed between nodes, allowing each node (or agent) to update it with partial results. You can think of it as a chain of actions, where each action contributes to solving a larger problem.\n",
    "\n",
    "### Example Use Cases\n",
    "\n",
    "- **Multi-agent Collaboration**: Multiple agents working together to solve a problem by performing different tasks, each contributing to the final solution.\n",
    "- **Data Processing Pipelines**: Complex workflows where each node processes and transforms data, passing the results to the next node.\n",
    "\n",
    "In this notebook, we will focus on building such a workflow and demonstrate how agents can communicate by reading from and writing to the shared state.\n",
    "\n",
    "![Multi Agent](images/multi-agent-tools.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "Before we begin, let's make sure your environment is set up correctly. We'll start by installing the necessary Python packages.\n",
    "\n",
    "### Installing Required Packages\n",
    "\n",
    "To get started, you'll need to install a few Python libraries. Run the following command to install them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in ./.conda/lib/python3.11/site-packages (0.2.16)\n",
      "Requirement already satisfied: langgraph in ./.conda/lib/python3.11/site-packages (0.2.16)\n",
      "Requirement already satisfied: langgraph-checkpoint-sqlite in ./.conda/lib/python3.11/site-packages (1.0.3)\n",
      "Requirement already satisfied: langchain_community in ./.conda/lib/python3.11/site-packages (0.2.16)\n",
      "Requirement already satisfied: requests in ./.conda/lib/python3.11/site-packages (2.32.3)\n",
      "Requirement already satisfied: termcolor in ./.conda/lib/python3.11/site-packages (2.4.0)\n",
      "Requirement already satisfied: wikipedia in ./.conda/lib/python3.11/site-packages (1.4.0)\n",
      "Requirement already satisfied: arxiv in ./.conda/lib/python3.11/site-packages (2.1.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.conda/lib/python3.11/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.conda/lib/python3.11/site-packages (from langchain) (2.0.34)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.conda/lib/python3.11/site-packages (from langchain) (3.10.5)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.38 in ./.conda/lib/python3.11/site-packages (from langchain) (0.2.38)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in ./.conda/lib/python3.11/site-packages (from langchain) (0.2.4)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in ./.conda/lib/python3.11/site-packages (from langchain) (0.1.110)\n",
      "Requirement already satisfied: numpy<2,>=1 in ./.conda/lib/python3.11/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in ./.conda/lib/python3.11/site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in ./.conda/lib/python3.11/site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<2.0.0,>=1.0.2 in ./.conda/lib/python3.11/site-packages (from langgraph) (1.0.8)\n",
      "Requirement already satisfied: aiosqlite<0.21.0,>=0.20.0 in ./.conda/lib/python3.11/site-packages (from langgraph-checkpoint-sqlite) (0.20.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./.conda/lib/python3.11/site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.conda/lib/python3.11/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.conda/lib/python3.11/site-packages (from requests) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.conda/lib/python3.11/site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.conda/lib/python3.11/site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: beautifulsoup4 in ./.conda/lib/python3.11/site-packages (from wikipedia) (4.12.3)\n",
      "Requirement already satisfied: feedparser~=6.0.10 in ./.conda/lib/python3.11/site-packages (from arxiv) (6.0.11)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.8)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in ./.conda/lib/python3.11/site-packages (from aiosqlite<0.21.0,>=0.20.0->langgraph-checkpoint-sqlite) (4.12.2)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.conda/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./.conda/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: sgmllib3k in ./.conda/lib/python3.11/site-packages (from feedparser~=6.0.10->arxiv) (1.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.conda/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.38->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./.conda/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.38->langchain) (24.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.conda/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.25.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.conda/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.conda/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./.conda/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./.conda/lib/python3.11/site-packages (from beautifulsoup4->wikipedia) (2.6)\n",
      "Requirement already satisfied: anyio in ./.conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.4.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./.conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\n",
      "Requirement already satisfied: sniffio in ./.conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.conda/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.conda/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.38->langchain) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.conda/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain langgraph langgraph-checkpoint-sqlite langchain_community requests termcolor wikipedia arxiv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuring a Simple Model\n",
    "\n",
    "In this section, we configure the machine learning model that our agent will use to process tasks. The `ModelService` class manages the interaction with the model (in this case, \"llama3.1:8b-instruct-fp16\"), allowing the agent to handle tasks such as listing VMs and retrieving details.\n",
    "\n",
    "### Model Configuration\n",
    "\n",
    "We initialize the `ModelService` with a specific model configuration, including parameters such as model endpoint, temperature (for controlling randomness), and others. This step enables our agent to perform model-based tasks using the provided configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from services.model_service import ModelService\n",
    "\n",
    "# Initialize the service with the model configuration\n",
    "ollama_service = ModelService(model=\"llama3.1:8b-instruct-fp16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Defining the Shared State\n",
    "\n",
    "In this step, we will define the shared state structure that the agents will use to communicate in the workflow. Each agent or node in the graph will read from this state, perform its task, and then update the state with new information. This shared state allows the agents to collaborate on solving a problem by contributing their partial results.\n",
    "\n",
    "### Shared State Structure\n",
    "\n",
    "We will use a custom class, `AgentGraphState`, to define the structure of the shared state. This class will store the input provided by the user and the responses from different agents. The key fields in our state will be:\n",
    "\n",
    "- **input**: The initial input provided by the user (e.g., a question or task).\n",
    "- **researcher_response**: A list that stores the responses from the \"researcher\" agent. This agent might be responsible for gathering relevant information or performing research.\n",
    "- **search_response**: A list that stores the results from the \"search\" agent, which can handle web searches or database queries.\n",
    "- **evaluator_response**: A list that stores the responses from the \"evaluator\" agent, which might be responsible for evaluating the quality of the search results.\n",
    "\n",
    "The fields `researcher_response`, `search_response` and `evaluator_response` are annotated with `add_messages`, which is a helper function that aggregates responses. This allows the agents to append new messages to the existing lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph.message import add_messages\n",
    "from typing import Annotated, TypedDict, Any\n",
    "\n",
    "\n",
    "class AgentGraphState(TypedDict):\n",
    "    input: str\n",
    "    researcher_response: Annotated[list, add_messages]\n",
    "    search_response: Annotated[list, add_messages]\n",
    "    evaluator_response: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating the State\n",
    "\n",
    "To allow agents to update the shared state, we will create a utility function, update_state. This function takes the current state, a key (the field in the state to be updated), and a value (the new data to be added).\n",
    "\n",
    "If the specified key exists in the state, the function updates it with the new value. If the key doesn't exist, the function issues a warning, ensuring that agents can only update pre-defined fields in the state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_state(state: AgentGraphState, key: str, value: Any):\n",
    "    \"\"\"\n",
    "    Update the state of the agent. Warn if the key doesn't exist.\n",
    "    \"\"\"\n",
    "    if key in state:\n",
    "        state[key] = value\n",
    "    else:\n",
    "        print(f\"Warning: Attempting to update a non-existing state key '{key}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating the Agents\n",
    "\n",
    "In this step, we will define the agents that will perform tasks within the graph. Each agent is responsible for using external tools to gather data, such as searching Wikipedia, querying Arxiv, or performing web searches. These agents will use the shared state to store their outputs and pass information to other agents in the workflow.\n",
    "\n",
    "### Agents Overview\n",
    "\n",
    "We will create two types of agents in this step:\n",
    "1. **Researcher Agent**: This agent will be responsible for gathering academic and knowledge-based information from sources like Wikipedia and Arxiv.\n",
    "2. **Search Agent**: This agent will handle web searches using tools like DuckDuckGo to retrieve information from the internet.\n",
    "3. **Evaluator Agent**: This agent will be responsible for evaluating the outputs of other agents in the workflow. It will use a set of rules to determine whether the output is relevant or not, and then update the shared state accordingly.\n",
    "\n",
    "Both agents will be built using the `ReactAgent` class, which can perform the **Thought → Action → Observation** loop, invoking external tools and storing the results in the shared state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring the Researcher Agent\n",
    "\n",
    "The researcher agent will use two tools:\n",
    "- **Wikipedia API**: We will configure this tool to return the top 1 result from Wikipedia, limiting the content length for concise responses.\n",
    "- **Arxiv API**: This tool will retrieve academic papers related to the query, again returning only the top 1 result.\n",
    "\n",
    "These tools are added to a list called `researcher_tools`, which will be used by the researcher agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "from langchain_community.tools import ArxivQueryRun\n",
    "\n",
    "api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=200)\n",
    "wiki = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "\n",
    "arxiv_wrapper = ArxivAPIWrapper(top_k_results=1, doc_content_chars_max=200)\n",
    "arxiv = ArxivQueryRun(api_wrapper=arxiv_wrapper)\n",
    "\n",
    "# Adding the search tool to the list of available tools\n",
    "researcher_tools = [arxiv, wiki]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent.react_agent import ReactAgent\n",
    "\n",
    "def researcher_node_function(state: AgentGraphState):\n",
    "    researcher_agent = ReactAgent(\n",
    "        state=state,\n",
    "        role=\"researcher\",\n",
    "        tools=researcher_tools,\n",
    "        ollama_service=ollama_service,\n",
    "    )\n",
    "\n",
    "    return researcher_agent.react(user_request=state[\"input\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring the Search Agent\n",
    "\n",
    "The search agent uses the **DuckDuckGo** search tool, which allows it to perform general web searches. The tool fetches relevant results from the internet based on the user query. This agent will store the search results in the `search_response` field of the shared state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "# Initialize DuckDuckGo Search Tool\n",
    "duckduckgo_search = DuckDuckGoSearchRun()\n",
    "\n",
    "search_tools = [duckduckgo_search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_node_function(state: AgentGraphState):\n",
    "    search_agent = ReactAgent(\n",
    "        state=state,\n",
    "        role=\"search\",\n",
    "        tools=search_tools,\n",
    "        ollama_service=ollama_service,\n",
    "    )\n",
    "\n",
    "    return search_agent.react(user_request=state[\"input\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Research and Search using an Evaluator Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_eval_user_request(state: AgentGraphState) -> str:\n",
    "    \"\"\"\n",
    "    Formulate a user request for the evaluation node, including the responses from both agents.\n",
    "\n",
    "    Parameters:\n",
    "    - state: The current state of the workflow containing the responses from both agents.\n",
    "    - input_query: The original user query.\n",
    "\n",
    "    Returns:\n",
    "    - str: The formatted evaluation request.\n",
    "    \"\"\"\n",
    "    # Retrieve the last entries from the researcher and search responses\n",
    "\n",
    "    last_research = state[\"researcher_response\"][-1].content\n",
    "    last_search = state[\"search_response\"][-1].content\n",
    "\n",
    "    # Formulate the user request including both agent responses\n",
    "    user_request = f\"\"\"\n",
    "    As an evaluator, your task is to analyze the responses from two agents based on the following query: '{state[\"input\"]}'.\n",
    "\n",
    "    Agents:\n",
    "    1. **Researcher Agent**: Uses academic and knowledge-based sources such as Wikipedia and Arxiv to provide answers.\n",
    "    2. **Search Agent**: Performs general web searches using DuckDuckGo to gather information.\n",
    "\n",
    "    Agent Responses:\n",
    "    - **Researcher Agent Response**: \n",
    "    '{last_research}'\n",
    "\n",
    "    - **Search Agent Response**:\n",
    "    '{last_search}'\n",
    "\n",
    "    Evaluation Criteria:\n",
    "    - **Accuracy**: How factually correct is the information provided by each agent?\n",
    "    - **Relevance**: How closely does each response align with the query?\n",
    "    - **Clarity and Conciseness**: How clear and concise is the explanation provided by each agent?\n",
    "\n",
    "    Instructions:\n",
    "    Please compare both responses based on the criteria above and determine which agent provided a better response. \n",
    "    Provide a detailed evaluation of each agent's response, and conclude which agent performed better overall and why.\n",
    "\n",
    "    Your output should include:\n",
    "    - A brief evaluation of each agent's response based on the criteria.\n",
    "    - A final decision on which agent's response was better, supported by clear reasons.\n",
    "    \"\"\"\n",
    "\n",
    "    return user_request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent.base_agent import Agent\n",
    "\n",
    "def eval_node_function(state: AgentGraphState):\n",
    "    eval_agent = Agent(\n",
    "        state=state,\n",
    "        role=\"evaluator\",\n",
    "        ollama_service=ollama_service,\n",
    "    )\n",
    "\n",
    "    return eval_agent.work(user_request=create_eval_user_request(state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How the Agents Work\n",
    "\n",
    "1. **Researcher Agent**:\n",
    "   - The researcher agent reads the `input` field from the shared state, which contains the user’s request.\n",
    "   - It then interacts with Wikipedia and Arxiv to gather relevant information.\n",
    "   - After processing the user request, the agent updates the `researcher_response` field in the state with the gathered data.\n",
    "\n",
    "2. **Search Agent**:\n",
    "   - The search agent also reads from the `input` field in the shared state.\n",
    "   - It uses DuckDuckGo to perform a web search based on the input and retrieves relevant results.\n",
    "   - The results are stored in the `search_response` field of the state.\n",
    "  \n",
    "3. **Evaluator Agent**:\n",
    "    - The evaluator agent reads `researcher_response` and `search_response` fields in the shared state.\n",
    "    - It then evaluates the user’s request based on the criteria.\n",
    "    - After processing the user request, it updates the `evaluator_response` field of the state with the evaluation results.\n",
    "\n",
    "By utilizing these agents, we can build a workflow where the agents collaborate to gather and process information from multiple sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Creating the Graph and Defining the Workflow\n",
    "\n",
    "In this step, we will define the **StateGraph** that orchestrates the workflow between the agents. The **StateGraph** represents the flow of tasks between the agents, allowing them to share a state and perform actions in a defined sequence. We will also introduce a checkpointing system using **SqliteSaver** to allow the graph to save and retrieve its state during execution.\n",
    "\n",
    "### Creating the Graph\n",
    "\n",
    "The **StateGraph** is the core structure that defines how different agents (nodes) interact with one another and pass the shared state along the workflow. We will:\n",
    "1. **Add Nodes**: The nodes in the graph represent the agents performing tasks. In our case, we add two nodes: the **researcher agent** and the **search agent**.\n",
    "2. **Define the Workflow**:\n",
    "   - The workflow starts with the **researcher agent**, which gathers academic or knowledge-based information.\n",
    "   - The results from the researcher agent are passed to the **search agent**, which performs a web search to gather additional information.\n",
    "   - The graph ends once the search agent has completed its task and updated the shared state with the results.\n",
    "\n",
    "By defining edges between the nodes, we can ensure that tasks are executed in a sequential manner, with each agent building upon the results from the previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "\n",
    "def create_graph() -> StateGraph:\n",
    "    \"\"\"\n",
    "    Create the state graph by defining nodes and edges.\n",
    "\n",
    "    Returns:\n",
    "    - StateGraph: The compiled state graph ready for execution.\n",
    "    \"\"\"\n",
    "    graph = StateGraph(AgentGraphState)\n",
    "\n",
    "    # Add nodes\n",
    "    graph.add_node(\"researcher_agent\", researcher_node_function)\n",
    "    graph.add_node(\"search_agent\", search_node_function)\n",
    "    graph.add_node(\"eval_agent\", eval_node_function)\n",
    "\n",
    "    # Define the flow of the graph\n",
    "    graph.add_edge(START, \"researcher_agent\")\n",
    "    graph.add_edge(START, \"search_agent\")\n",
    "    graph.add_edge(\"researcher_agent\", \"eval_agent\")\n",
    "    graph.add_edge(\"search_agent\", \"eval_agent\")\n",
    "    graph.add_edge(\"eval_agent\", END)\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpointing with SqliteSaver\n",
    "\n",
    "To add persistence and fault tolerance to our workflow, we will integrate a **checkpointing system** using **SqliteSaver**. This allows the state graph to save its progress in an in-memory SQLite database, which can later be retrieved or resumed if necessary.\n",
    "\n",
    "The checkpointing system:\n",
    "- **Saves the State**: It stores the state of the graph and its nodes, allowing the workflow to be paused and resumed.\n",
    "- **Memory-Based Storage**: For simplicity, we will use an in-memory SQLite database (`\":memory:\"`), but this can be replaced with a persistent database for long-term storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "def from_conn_stringx(\n",
    "    cls,\n",
    "    conn_string: str,\n",
    ") -> \"SqliteSaver\":\n",
    "    return SqliteSaver(conn=sqlite3.connect(conn_string, check_same_thread=False))\n",
    "\n",
    "\n",
    "SqliteSaver.from_conn_stringx = classmethod(from_conn_stringx)\n",
    "\n",
    "memory = SqliteSaver.from_conn_stringx(\":memory:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Executing the Workflow and Handling State Changes\n",
    "\n",
    "In this final step, we will compile the graph, execute the multi-agent workflow, and monitor the state changes as the agents process the user query. Additionally, we will use a custom serializer to handle and inspect the agent's state at various points in the workflow.\n",
    "\n",
    "![workflow](images/workflow-search.png)\n",
    "\n",
    "### Creating and Compiling the Workflow\n",
    "\n",
    "Once the **StateGraph** is defined and nodes are connected, the next step is to **compile** the graph into a runnable workflow. This is achieved using the `compile` method, which transforms the graph into an executable state.\n",
    "\n",
    "- **Checkpointing**: The workflow uses the **SqliteSaver** to checkpoint the state during execution, ensuring that we can pause and resume the workflow if needed.\n",
    "- **Interrupt Before**: We define an interrupt point before the **search agent** node, which means the workflow can be paused just before this agent runs, giving us the option to inspect or modify the state.\n",
    "\n",
    "### Workflow Parameters\n",
    "\n",
    "Before executing the workflow, we configure several parameters:\n",
    "- **iterations**: Defines the number of times the workflow will run. In this case, we set it to 10 iterations to allow for multiple rounds of processing.\n",
    "- **verbose**: If set to `True`, this flag will print detailed information about each event (i.e., what each agent is doing and the state updates).\n",
    "- **config**: This dictionary contains configurable options, such as `thread_id`, which may be used by agents during task execution.\n",
    "\n",
    "### Example Query\n",
    "\n",
    "For this example, we define a query:\n",
    "- **\"Who is the USA's President?\"** — This will be the input provided to the agents. The agents will use this query to gather relevant information from the tools (e.g., Wikipedia, Arxiv, DuckDuckGo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph and workflow created.\n"
     ]
    }
   ],
   "source": [
    "# Create the graph and compile the workflow\n",
    "graph = create_graph()\n",
    "workflow = graph.compile(checkpointer=memory, interrupt_before=[\"eval_agent\"])\n",
    "print(\"Graph and workflow created.\")\n",
    "\n",
    "# Define workflow parameters\n",
    "iterations = 10\n",
    "verbose = True\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "query = \"Who's the USA's President?\"\n",
    "dict_inputs = {\"input\": query}\n",
    "limit = {\"recursion_limit\": iterations}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing the Workflow\n",
    "\n",
    "Once the workflow is compiled, we execute it using the `stream` method, which iterates through each node in the graph and processes the input. At each step:\n",
    "- The current event (i.e., agent action) is printed, showing what the agent is doing and how the state is changing.\n",
    "- State changes are printed in real-time, allowing us to observe how the agents update the shared state with new information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m<|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Who's the USA's President?<|eot_id|>\u001b[0m\u001b[32m<|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Who's the USA's President?<|eot_id|>\u001b[0m\n",
      "\n",
      "\u001b[36m<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\n",
      "    \"thought\": \"To find out who the current president of the United States is, I need to look up the information.\",\n",
      "    \"action\": \"wikipedia\",\n",
      "    \"action_input\": {\n",
      "        \"query\": {\n",
      "            \"title\": \"List of Presidents of the United States by date\",\n",
      "            \"description\": \"\"\n",
      "        }\n",
      "    }\n",
      "}<|eot_id|>\u001b[0m\n",
      "\u001b[35m<|python_tag|>wikipedia.call({'query': {'title': 'List of Presidents of the United States by date', 'description': ''}})\n",
      "<|eom_id|>\u001b[0m\n",
      "\u001b[33m<|start_header_id|>ipython<|end_header_id|>\n",
      "\n",
      "{\n",
      "    \"observation\": \"Error executing tool wikipedia: 1 validation error for WikipediaQueryInput\\nquery\\n  str type expected (type=type_error.str)\"\n",
      "}<|eot_id|>\u001b[0m\n",
      "\u001b[36m<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\n",
      "    \"thought\": \"To find out who is currently the President of the United States, I need to search for this information.\",\n",
      "    \"action\": \"duckduckgo_search\",\n",
      "    \"action_input\": {\n",
      "        \"query\": {\n",
      "            \"title\": \"Current US President\",\n",
      "            \"description\": \"Search for the current President of the United States\",\n",
      "            \"type\": \"string\"\n",
      "        }\n",
      "    }\n",
      "}<|eot_id|>\u001b[0m\n",
      "\u001b[35m<|python_tag|>duckduckgo_search.call({'query': {'title': 'Current US President', 'description': 'Search for the current President of the United States', 'type': 'string'}})\n",
      "<|eom_id|>\u001b[0m\n",
      "\u001b[33m<|start_header_id|>ipython<|end_header_id|>\n",
      "\n",
      "{\n",
      "    \"observation\": \"Error executing tool duckduckgo_search: 1 validation error for DDGInput\\nquery\\n  str type expected (type=type_error.str)\"\n",
      "}<|eot_id|>\u001b[0m\n",
      "\u001b[36m<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\n",
      "    \"thought\": \"I need to provide a valid string query to the Wikipedia API.\",\n",
      "    \"action\": \"wikipedia\",\n",
      "    \"action_input\": {\n",
      "        \"query\": {\n",
      "            \"title\": \"Current President of the United States\"\n",
      "        }\n",
      "    }\n",
      "}<|eot_id|>\u001b[0m\n",
      "\u001b[35m<|python_tag|>wikipedia.call({'query': {'title': 'Current President of the United States'}})\n",
      "<|eom_id|>\u001b[0m\n",
      "\u001b[33m<|start_header_id|>ipython<|end_header_id|>\n",
      "\n",
      "{\n",
      "    \"observation\": \"Error executing tool wikipedia: 1 validation error for WikipediaQueryInput\\nquery\\n  str type expected (type=type_error.str)\"\n",
      "}<|eot_id|>\u001b[0m\n",
      "\u001b[36m<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\n",
      "    \"thought\": \"The previous attempt to search for the current US President failed due to a query format issue. I need to reformulate the query in the correct string format.\",\n",
      "    \"action\": \"duckduckgo_search\",\n",
      "    \"action_input\": {\n",
      "        \"query\": \"Current president of the United States\"\n",
      "    }\n",
      "}<|eot_id|>\u001b[0m\n",
      "\u001b[35m<|python_tag|>duckduckgo_search.call({'query': 'Current president of the United States'})\n",
      "<|eom_id|>\u001b[0m\n",
      "\u001b[35m<|start_header_id|>ipython<|end_header_id|>\n",
      "\n",
      "This web page provides a comprehensive list of all the presidents of the United States from 1789 to the present, with their portraits, terms, parties, and vice presidents. The current president is Joe Biden, who assumed office on January 20, 2021. Sept. 10. 4% Kennedy. 47% Trump. 49% Harris. Nate Cohn Chief political analyst. Kamala Harris and Donald J. Trump are locked in an extremely tight contest heading into their first debate Tuesday ... CNN coverage of Joseph R. Biden, the 46th president of the United States As the head of the government of the United States, the president is arguably the most powerful government official in the world. The president is elected to a four-year term via an electoral college system. Since the Twenty-second Amendment was adopted in 1951, the American presidency has been limited to a maximum of two terms.. Click on a president below to learn more about each presidency ... O n November 5th Americans will go to the polls to elect their next president. Until June 27th it seemed that the match-up would be between the same two candidates as in 2020: Joe Biden, the ...<|eot_id|>\u001b[0m\n",
      "\u001b[33m<|start_header_id|>ipython<|end_header_id|>\n",
      "\n",
      "{\n",
      "    \"observation\": \"This web page provides a comprehensive list of all the presidents of the United States from 1789 to the present, with their portraits, terms, parties, and vice presidents. The current president is Joe Biden, who assumed office on January 20, 2021. Sept. 10. 4% Kennedy. 47% Trump. 49% Harris. Nate Cohn Chief political analyst. Kamala Harris and Donald J. Trump are locked in an extremely tight contest heading into their first debate Tuesday ... CNN coverage of Joseph R. Biden, the 46th president of the United States As the head of the government of the United States, the president is arguably the most powerful government official in the world. The president is elected to a four-year term via an electoral college system. Since the Twenty-second Amendment was adopted in 1951, the American presidency has been limited to a maximum of two terms.. Click on a president below to learn more about each presidency ... O n November 5th Americans will go to the polls to elect their next president. Until June 27th it seemed that the match-up would be between the same two candidates as in 2020: Joe Biden, the ...\"\n",
      "}<|eot_id|>\u001b[0m\n",
      "\u001b[36m<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\n",
      "    \"thought\": \"The previous query did not provide a valid string. I need to find the correct format.\",\n",
      "    \"action\": \"wikipedia\",\n",
      "    \"action_input\": {\n",
      "        \"query\": \"current president of the United States\"\n",
      "    }\n",
      "}<|eot_id|>\u001b[0m\n",
      "\u001b[35m<|python_tag|>wikipedia.call({'query': 'current president of the United States'})\n",
      "<|eom_id|>\u001b[0m\n",
      "\u001b[35m<|start_header_id|>ipython<|end_header_id|>\n",
      "\n",
      "Page: President of the United States\n",
      "Summary: The president of the United States (POTUS) is the head of state and head of government of the United States of America. The president directs the executiv<|eot_id|>\u001b[0m\n",
      "\u001b[33m<|start_header_id|>ipython<|end_header_id|>\n",
      "\n",
      "{\n",
      "    \"observation\": \"Page: President of the United States\\nSummary: The president of the United States (POTUS) is the head of state and head of government of the United States of America. The president directs the executiv\"\n",
      "}<|eot_id|>\u001b[0m\n",
      "\u001b[36m<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\n",
      "    \"thought\": \"The current President of the United States is mentioned in the search result as Joe Biden.\",\n",
      "    \"answer\": \"I have the answer: Joe Biden.\"\n",
      "}<|eot_id|>\u001b[0m\n",
      "\n",
      "Event: {'search_agent': {'search_response': AIMessage(content='I have the answer: Joe Biden.')}}\n",
      "\u001b[36m<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\n",
      "    \"answer\": \"I have the answer: The current job description for the President of the United States.\"\n",
      "}<|eot_id|>\u001b[0m\n",
      "\n",
      "Event: {'researcher_agent': {'researcher_response': AIMessage(content='I have the answer: The current job description for the President of the United States.')}}\n"
     ]
    }
   ],
   "source": [
    "# Execute the workflow and print state changes\n",
    "for event in workflow.stream(dict_inputs, config):\n",
    "    if verbose:\n",
    "        print(\"\\nEvent:\", event)\n",
    "    else:\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the Final State\n",
    "\n",
    "At the end of the workflow, we capture a **snapshot of the state** using the `get_state` method. This snapshot contains all the information gathered by the agents during the workflow execution. We use a **custom serializer** to serialize the state, making it easy to inspect the contents, such as responses from the agents.\n",
    "\n",
    "The state snapshot includes:\n",
    "- **Agent Messages**: These are the interactions between agents and tools, captured as `AIMessage` or `SystemMessage` objects. We use a custom serializer to format these messages for easier readability.\n",
    "- **Next Node**: Indicates the next node in the workflow, if any, to show where the workflow will continue from if it hasn't finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"input\": \"Who's the USA's President?\",\n",
      "    \"researcher_response\": [\n",
      "        {\n",
      "            \"content\": \"I have the answer: The current job description for the President of the United States.\",\n",
      "            \"id\": \"9790cbf3-1cb7-4cee-9acd-2a4802702715\"\n",
      "        }\n",
      "    ],\n",
      "    \"search_response\": [\n",
      "        {\n",
      "            \"content\": \"I have the answer: Joe Biden.\",\n",
      "            \"id\": \"3b42e389-f6fe-4492-95f8-ca3e62220af3\"\n",
      "        }\n",
      "    ],\n",
      "    \"evaluator_response\": []\n",
      "}\n",
      "('eval_agent',)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from langchain_core.messages.ai import AIMessage\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "\n",
    "def custom_serializer(obj):\n",
    "    if isinstance(obj, AIMessage):\n",
    "        return {\n",
    "            \"content\": obj.content,\n",
    "            \"id\": obj.id,\n",
    "            # Add other attributes as needed\n",
    "        }\n",
    "    elif isinstance(obj, SystemMessage):\n",
    "        return {\n",
    "            \"content\": obj.content,\n",
    "            \"id\": obj.id,\n",
    "            # Add other attributes as needed\n",
    "        }\n",
    "    # Add other custom class serializations here\n",
    "    else:\n",
    "        return str(obj)  # Fallback to string conversion if not recognized\n",
    "\n",
    "\n",
    "state_snapshot = workflow.get_state(config)\n",
    "\n",
    "print(json.dumps(state_snapshot.values, indent=4, default=custom_serializer))\n",
    "\n",
    "print(state_snapshot.next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-executing the Workflow\n",
    "\n",
    "Finally, the workflow can be re-executed by running the `stream` method again. This allows you to modify configurations, input, or parameters and observe how the agents behave under different conditions.\n",
    "\n",
    "By the end of this step, we have a fully functioning multi-agent workflow that can process complex queries, gather information, and update its shared state accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Event: {'eval_agent': {'evaluator_response': AIMessage(content='{\\n    \"Evaluator\\'s Analysis\": {\\n        \"Researcher Agent Response Evaluation\": {\\n            \"Accuracy\": 0,\\n            \"Relevance\": 6,\\n            \"Clarity and Conciseness\": 4\\n        },\\n        \"Search Agent Response Evaluation\": {\\n            \"Accuracy\": 8,\\n            \"Relevance\": 9,\\n            \"Clarity and Conciseness\": 9\\n        }\\n    },\\n    \"Conclusion\": {\\n        \"Winner: Search Agent\": [\\n            \"The Search Agent\\'s response is more accurate as it directly answers the query with the name of the current President.\",\\n            \"In terms of relevance, the Researcher Agent\\'s response doesn\\'t provide any relevant information to answer the question, whereas the Search Agent provides a clear and direct response.\",\\n            \"Both agents could improve their clarity and conciseness. The Researcher Agent\\'s response does not directly address the query, while the Search Agent\\'s is concise but does not explain how it got its answer.\"\\n        ]\\n    }\\n}')}}\n"
     ]
    }
   ],
   "source": [
    "# Execute the workflow and print state changes\n",
    "for event in workflow.stream(None, config):\n",
    "    if verbose:\n",
    "        print(\"\\nEvent:\", event)\n",
    "    else:\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"input\": \"Who's the USA's President?\",\n",
      "    \"researcher_response\": [\n",
      "        {\n",
      "            \"content\": \"I have the answer: The current job description for the President of the United States.\",\n",
      "            \"id\": \"9790cbf3-1cb7-4cee-9acd-2a4802702715\"\n",
      "        }\n",
      "    ],\n",
      "    \"search_response\": [\n",
      "        {\n",
      "            \"content\": \"I have the answer: Joe Biden.\",\n",
      "            \"id\": \"3b42e389-f6fe-4492-95f8-ca3e62220af3\"\n",
      "        }\n",
      "    ],\n",
      "    \"evaluator_response\": [\n",
      "        {\n",
      "            \"content\": \"{\\n    \\\"Evaluator's Analysis\\\": {\\n        \\\"Researcher Agent Response Evaluation\\\": {\\n            \\\"Accuracy\\\": 0,\\n            \\\"Relevance\\\": 6,\\n            \\\"Clarity and Conciseness\\\": 4\\n        },\\n        \\\"Search Agent Response Evaluation\\\": {\\n            \\\"Accuracy\\\": 8,\\n            \\\"Relevance\\\": 9,\\n            \\\"Clarity and Conciseness\\\": 9\\n        }\\n    },\\n    \\\"Conclusion\\\": {\\n        \\\"Winner: Search Agent\\\": [\\n            \\\"The Search Agent's response is more accurate as it directly answers the query with the name of the current President.\\\",\\n            \\\"In terms of relevance, the Researcher Agent's response doesn't provide any relevant information to answer the question, whereas the Search Agent provides a clear and direct response.\\\",\\n            \\\"Both agents could improve their clarity and conciseness. The Researcher Agent's response does not directly address the query, while the Search Agent's is concise but does not explain how it got its answer.\\\"\\n        ]\\n    }\\n}\",\n",
      "            \"id\": \"df8d4825-bda4-4b6b-b8ca-66c02c5879ff\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "final_state = workflow.get_state(config)\n",
    "\n",
    "print(json.dumps(final_state.values, indent=4, default=custom_serializer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mUser Query: Who's the USA's President?\n",
      "\u001b[0m\n",
      "\u001b[33mResearcher Agent Response:\u001b[0m\n",
      "\u001b[33m================================== Ai Message ==================================\n",
      "\n",
      "I have the answer: The current job description for the President of the United States.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[35mSearch Agent Response:\u001b[0m\n",
      "\u001b[35m================================== Ai Message ==================================\n",
      "\n",
      "I have the answer: Joe Biden.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[36mEvaluator Agent Response:\u001b[0m\n",
      "\u001b[36m================================== Ai Message ==================================\n",
      "\n",
      "{\n",
      "    \"Evaluator's Analysis\": {\n",
      "        \"Researcher Agent Response Evaluation\": {\n",
      "            \"Accuracy\": 0,\n",
      "            \"Relevance\": 6,\n",
      "            \"Clarity and Conciseness\": 4\n",
      "        },\n",
      "        \"Search Agent Response Evaluation\": {\n",
      "            \"Accuracy\": 8,\n",
      "            \"Relevance\": 9,\n",
      "            \"Clarity and Conciseness\": 9\n",
      "        }\n",
      "    },\n",
      "    \"Conclusion\": {\n",
      "        \"Winner: Search Agent\": [\n",
      "            \"The Search Agent's response is more accurate as it directly answers the query with the name of the current President.\",\n",
      "            \"In terms of relevance, the Researcher Agent's response doesn't provide any relevant information to answer the question, whereas the Search Agent provides a clear and direct response.\",\n",
      "            \"Both agents could improve their clarity and conciseness. The Researcher Agent's response does not directly address the query, while the Search Agent's is concise but does not explain how it got its answer.\"\n",
      "        ]\n",
      "    }\n",
      "}\u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from termcolor import colored\n",
    "\n",
    "# Print the user input\n",
    "print(colored(f\"User Query: {final_state.values['input']}\\n\",\"green\"))\n",
    "\n",
    "# Print the researcher agent's response\n",
    "print(colored(\"Researcher Agent Response:\", \"yellow\"))\n",
    "if final_state.values[\"researcher_response\"]:\n",
    "    for message in final_state.values[\"researcher_response\"]:\n",
    "        if isinstance(message, AIMessage):\n",
    "            pretty_message = message.pretty_repr()\n",
    "            print(colored(f\"{pretty_message}\", \"yellow\"))\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Print the researcher agent's response\n",
    "print(colored(\"Search Agent Response:\", \"magenta\"))\n",
    "if final_state.values[\"search_response\"]:\n",
    "    for message in final_state.values[\"search_response\"]:\n",
    "        if isinstance(message, AIMessage):\n",
    "            pretty_message = message.pretty_repr()\n",
    "            print(colored(f\"{pretty_message}\", \"magenta\"))\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Print the researcher agent's response\n",
    "print(colored(\"Evaluator Agent Response:\", \"cyan\"))\n",
    "if final_state.values[\"evaluator_response\"]:\n",
    "    for message in final_state.values[\"evaluator_response\"]:\n",
    "        if isinstance(message, AIMessage):\n",
    "            pretty_message = message.pretty_repr()\n",
    "            print(colored(f\"{pretty_message}\", \"cyan\"))\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
